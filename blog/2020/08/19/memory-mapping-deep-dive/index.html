<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=3">
<meta httpequiv="x-ua-compatible" content="ie=edge">
<meta property="og:type" content="website">
<meta name="author" content="turpleio">
<meta name="generator" content="Docusaurus v2.0.0-alpha.75">
<link href="https://www.googletagmanager.com" rel="dns-prefetch">
<link href="https://www.google-analytics.com" rel="dns-prefetch">
<link rel="icon" href="/favicon.png">
<link rel="apple-touch-icon" href="/img/icons/apple-180x180.png" sizes="180x180">
<meta name="msapplication-config" content="/browserconfig.xml">
<link rel="sitemap" type="application/xml" href="/sitemap.xml">
<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=GTM-PVR7M2G"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","GTM-PVR7M2G",{anonymize_ip:!0})</script>
<link rel="search" type="application/opensearchdescription+xml" title="Turple: Cloud Native Platform" href="/opensearch.xml">
<link rel="manifest" href="/manifest.webmanifest">
<meta name="theme-color" content="#d14671">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#21222c">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Turple: Cloud Native Platform Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Turple: Cloud Native Platform Blog Atom Feed"><title data-react-helmet="true">Re-examining our approach to memory mapping | Turple: Cloud Native Platform</title><meta data-react-helmet="true" property="og:title" content="Re-examining our approach to memory mapping | Turple: Cloud Native Platform"><meta data-react-helmet="true" name="description" content="What we learned by re-examining our approach to memory mapping. A low level implementation, as close as posibble to the kernel, enabled even greater performance."><meta data-react-helmet="true" name="twitter:description" content="What we learned by re-examining our approach to memory mapping. A low level implementation, as close as posibble to the kernel, enabled even greater performance."><meta data-react-helmet="true" property="og:description" content="What we learned by re-examining our approach to memory mapping. A low level implementation, as close as posibble to the kernel, enabled even greater performance."><meta data-react-helmet="true" name="twitter:title" content="Re-examining our approach to memory mapping | Turple: Cloud Native Platform"><meta data-react-helmet="true" name="twitter:image:alt" content="Image for &quot;Re-examining our approach to memory mapping | Turple: Cloud Native Platform&quot;"><meta data-react-helmet="true" name="keywords" content="performance,questdb,database,tutorial"><meta data-react-helmet="true" property="og:image" content="https://turpleio.github.io/img/blog/2020-08-19/banner.jpg"><meta data-react-helmet="true" name="twitter:image" content="https://turpleio.github.io/img/blog/2020-08-19/banner.jpg"><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><link rel="stylesheet" href="/assets/css/styles.4f6557e4.css">
</head>
<body itemscope itemtype="http://schema.org/Organization">
<meta itemprop="name" content="Turple: Cloud Native Platform">
<meta itemprop="description" content="Turple is a cloud native platform which can help you build and operate your services on cloud.">
<meta itemprop="url" content="https://turpleio.github.io">
<meta itemprop="logo" content="https://turpleio.github.io/img/favicon.png">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"dark")}()</script><div id="__docusaurus">
<nav class="navbar navbar_wBc8 navbar--light"><div class="navbar__inner inner_Y8Z6"><div class="navbar__items"><div aria-label="Navigation bar toggle" class="navbar__toggle" role="button" tabindex="0"><svg xmlns="http://www.w3.org/2000/svg" width="30" height="30" viewBox="0 0 30 30" role="img" focusable="false"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></div><a class="navbar__brand brand_AtiA" href="/">QuestDB</a></div><div class="navbar__items navbar__items--right"></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div><div class="navbar-sidebar"><div class="navbar-sidebar__brand"><a class="navbar__brand brand_AtiA" href="/">QuestDB</a></div><div class="navbar-sidebar__items"><div class="menu"><ul class="menu__list"></ul></div></div></div></nav><div class="wrapper_DIJ0 blog-wrapper"><div class="container margin-vert--lg"><div class="row"><div class="col col--3"><div class="sidebar_q+wC thin-scrollbar"><h3 class="sidebarItemTitle_9G5K">Recent posts</h3><ul class="sidebarItemList_6T4b"><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/2022/12/19/merry-questmas-gifts-2023">Merry Questmas! Here are your gifts for 2023...</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/2022/12/13/using-prometheus-loki-grafana-monitor-questdb-kubernetes">Using Prometheus, Loki, and Grafana to monitor QuestDB in Kubernetes</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/2022/11/30/full-table-scan-are-fast">Listen to Your CPU - Full-table Scans Are Fast</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/2022/11/25/questdb-6.6.1-dynamic-commits">QuestDB 6.6.1 - Dynamic Commits</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/2022/11/23/sql-extensions-time-series-data-questdb-part-ii">SQL Extensions for Time Series Data in QuestDB - Part II</a></li></ul></div></div><main class="col col--7"><article><header><h1 class="title_KBQu">Re-examining our approach to memory mapping</h1><time datetime="2020-08-19T00:00:00.000Z" class="date_A31P">August 19, 2020 Â· 11 min read</time><div class="avatar margin-vert--md"><a href="https://github.com/davidgs" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img src="https://avatars.githubusercontent.com/davidgs" alt="David G. Simmons"></a><div class="avatar__intro"><h4 class="avatar__name"><a href="https://github.com/davidgs" target="_blank" rel="noopener noreferrer">David G. Simmons</a></h4><small class="avatar__subtitle">QuestDB Team</small></div></div></header><div class="markdown"><figure><img alt="Hand holding an analog stopwatch" class="image_1-Fc image--title_Z46g" height="433" src="/img/blog/2020-08-19/banner.jpg" width="650"><figcaption class="caption_VLGg"> Photo by<a href="https://unsplash.com/photos/p3Pj7jOYvnM" target="_blank" rel="noopener noreferrer">Veri Ivanova</a> on <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a> </figcaption></figure><p>How does QuestDB get the kind of performance it does, and how are we continuing
to squeeze another 50-60% out of it? This post will look at a code change we
thought would create a negative performance impact, which actually brought a
substantial boost in the system&#x27;s overall performance and demonstrates that we
are constantly learning more about performance improvements.</p><p>If you like this content, show it with a star on
<a href="https://github.com/questdb/questdb" target="_blank" rel="noopener noreferrer">GitHub</a> or come say hi in our
<a href="https://" target="_blank" rel="noopener noreferrer">community Slack</a> workspace.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="how-to-improve-time-series-performance"></a>How to improve time series performance<a class="hash-link" href="#how-to-improve-time-series-performance" title="Direct link to heading">#</a></h2><p>QuestDB started out with a single-threaded approach to queries and such. But one
obvious way to improve performance in a Java application like this is to
parallelize as much as you can by using multiple threads of execution.</p><p>I&#x27;ve written multi-threaded applications, and they are not easy to do. It&#x27;s hard
to coordinate the work between multiple threads, and to make sure that there are
no race conditions, collisions, etc.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="how-to-store-time-series-data-more-efficiently"></a>How to store time series data more efficiently<a class="hash-link" href="#how-to-store-time-series-data-more-efficiently" title="Direct link to heading">#</a></h2><p>So first it&#x27;s important to understand that QuestDB stores it&#x27;s data in columnar
format. We store each column of data in a file. So for every column of data,
there is a file.</p><p>We then split those columns up into data frames that are independent and can be
computed completely independently of each other.</p><p>The problem we encountered with this framing scheme was that it was impossible
to frame variable length data. Data spilled out of the frame, making it
difficult to manage.</p><p>You see, we store fixed length fields with fixed length values, such that
aligning frames to 8 bytes would ensure that all our fixed length data does not
straddle frames. Hence all the columns are the same frame width. But strings and
blobs can&#x27;t be forced into 8 bytes without making them useless.</p><p>So we could extract extreme performance out of all the fixed-length values, but
these variable-length values dragged the performance back down.</p><p>Which brings us to pages and how data is referenced in memory.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="can-memory-mapped-pages-be-more-efficient"></a>Can memory-mapped pages be more efficient?<a class="hash-link" href="#can-memory-mapped-pages-be-more-efficient" title="Direct link to heading">#</a></h2><p>QuestDB uses memory-mapped pages to reference data in order to make it really
fast. If you&#x27;re dividing up your data into pages, and all data has a fixed
length, then it&#x27;s relatively easy to ensure that you don&#x27;t have data that spans
multiple pages. You just break pages at multiples of 8-bytes and everything will
fit within page boundaries.</p><p>When you add variable-length data, suddenly you cannot ensure that everything
will line up along page boundaries and you will have the very real possibility
-- actually a certainty -- that you may have to jump from one page to another
just to get all the data contained in a frame.</p><p>This, it turns out, is hugely inefficient. If (data is in frame) then (process
that data) else (figure out where the rest of the data is, get that, then
process it all). This kind of if-then-else sprinkled throughout the code is a)
hard to debug and b) leads to lots of branching, which slows down execution.</p><p>In order to prevent variable length data from straddling frames we would need to
have different frame lengths per column. Furthermore, calculating aligned frame
lengths for variable length data is non trivial and requires scanning the entire
data set which would reversing any performance gains from parallelization.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="one-page-to-rule-them-all"></a>One page to rule them all<a class="hash-link" href="#one-page-to-rule-them-all" title="Direct link to heading">#</a></h2><p>(Yes, I just made a <em>The Highlander</em>
<a href="https://en.wikipedia.org/wiki/Highlander_(film)" target="_blank" rel="noopener noreferrer">reference</a>)</p><p>What if, in order to get around data being on multiple pages, we simply used
<em>one</em> page for all of the data? Of course my first question was &quot;Don&#x27;t you at
some point reach a limit on the page size?&quot; but Vlad and Patrick assured me
there is, indeed, no limit on a page size.</p><p>If your page size is bigger than the available memory, the kernel will handle
swapping pages in and out for you as you try to access different parts of the
page. So of course I asked &quot;well then, why didn&#x27;t you do this from the
beginning?&quot;</p><p>Vlad, in his typically self-deprecating style, just said &quot;We didn&#x27;t know. We
thought we should keep them to a certain size to keep them from growing out of
control&quot; which, quite frankly, seems like the right answer.</p><p>We&#x27;d just resize those smaller pages as needed. But as Vlad explained, if you do
that then you need to copy the data over to the new, resized page and &quot;copying
can take over your life.&quot; Databases aren&#x27;t built to maximize the efficiency of
data copying. They are built to maximize the ability to extract value from data.
Copying data from one page to another isn&#x27;t extracting value.</p><p>So they tried just allocating a new page, and jumping from one page to the next
as needed to find the required data. This cut down on the copying of data, but
it lead to the problems outlined in the previous section. You never knew which
page your data was going to be on, and jumping from one page to another was
hugely inefficient.</p><p>So they tried having just the one page. One massive page (that you can grow as
needed, without copying data around). Vlad, again in his style, said the
performance turned out to be &quot;not bad&quot; with this approach. And by &quot;not bad&quot; he
of course meant about a 60% performance improvement.</p><p>When you get into using one single page, of course the total available address
space comes into play. But since QuestDB only runs on 64-bit architectures, we
have 2^64 address space, which is more than enough.</p><p>This is where Patrick jumped in to explain that when you have an area of memory
mapped from a file, when the file grows you remap the new size into memory. The
operating system does not need to copy anything; the virtual memory model allows
the OS to just remap the already mapped pages into the newly mapped memory
region. In many cases, the OS may have already reserved the entire address space
for you so your new mapping is in the same region as the old, just bigger.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="how-kernels-handle-pages-efficiently"></a>How kernels handle pages efficiently<a class="hash-link" href="#how-kernels-handle-pages-efficiently" title="Direct link to heading">#</a></h2><p>The kernel allocates a full sized address space for your file when you requested
the memory-mapped file. And apparently this is true across Linux, macOS and
Windows. So from that point on, there&#x27;s really no further copying that needs to
happen.</p><p>Furthermore, the kernel is going to handle paging parts of that file in and out
of memory as needed. Now, I&#x27;m old-school Unix, and page-swapping which lead to
thrashing was always something we worried about back in the olden days. So I
asked about it. According to Patrick, this could only happen really if you have
a massive file that you are reading basically randomly at high speed. Other than
that, the kernel will handle reading ahead and pre-loading pages as needed in
order to be as efficient as possible.</p><p>Kernels, it turns out, are smart. In fact, kernels are basically smarter than
you or I will ever hope to be. They&#x27;ve been developed across decades to be
hugely efficient at doing these things. It&#x27;s what they do. The kernel will
memory map the file into the file cache and even if it needs to move stuff
around, it can move the logical address and it&#x27;s still the same underlying
physical memory pages.</p><p>If you think that you can take over caching the data from the OS and do a better
job of managing the memory space, and the allocation and re-allocation of the
memory, you&#x27;re wrong. Again, this is what the Kernel does, and at some level,
even if you try to take this job away from the kernel, it is <em>still</em> doing some
amount of it anyway. So your attempts to take this memory management and
allocation away from the kernel has done little more than just add another layer
on top of what the kernel is doing anyway. Another layer on top of something is
basically never more efficient than the original thing.</p><p>When you read an offset into a file, you send a buffer to read into, the address
to start reading at, and the offset into the file. Now, the kernel is going to
cache all of that for you as you do it, because that&#x27;s the kernel&#x27;s job, really.
But many database developers then take that, and cache it themselves, with their
own caching scheme.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="how-fast-can-you-go-with-database-speed"></a>How fast can you go with database speed?<a class="hash-link" href="#how-fast-can-you-go-with-database-speed" title="Direct link to heading">#</a></h2><p>When I asked Vlad about this, and how it relates to query speed, he was quite
explicit in saying that thinking you (a database developer) can beat the kernel
is pure folly. Postgres tries this and, according to Vlad, an aggregation over a
large (really large!) dataset can take 5 <em>minutes</em>, whereas the same aggregation
on QuestDB takes only 60ms. Those aren&#x27;t typos.</p><p>To both Patrick and Vlad (and me, for what that&#x27;s worth), the idea that we, as
developers, can be better at these operations than the kernel (when really we&#x27;re
doing them <em>on top of</em> the kernel anyway) is simply ridiculous. If I take an
army of researchers and spend a decade of development, then <em>maybe</em> I can do it
better than the kernel, but during that time guess what? The army of people
working on the kernel will have found further improvements and left me behind
anyway.</p><p>It comes down to letting the kernel do its job, and us doing ours. And our job
is to exploit the kernel for every ounce of performance we can get out of it
without trying to do it&#x27;s job for it.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="performance-benchmark-results"></a>Performance benchmark results<a class="hash-link" href="#performance-benchmark-results" title="Direct link to heading">#</a></h2><p>When it comes to performance claims, we always try to back them up with actual
numbers that can be replicated. You can run these tests yourself, and you can
always go and look at the
<a href="https://github.com/questdb/questdb/tree/master/benchmarks/src/main/java/org/questdb" target="_blank" rel="noopener noreferrer">source code</a>
for these tests to see how they are implemented.</p><p>We think these numbers speak for themselves.</p><p>These first results are for the primitives and represent 10,000 reads/writes:</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="32-bit-read"></a>32-bit Read<a class="hash-link" href="#32-bit-read" title="Direct link to heading">#</a></h3><table><thead><tr><th>Benchmark</th><th>Mode</th><th>Cnt</th><th>Score</th><th>Units</th></tr></thead><tbody><tr><td>VirtualMemoryReadBenchmark.testIntContiguous</td><td>avgt</td><td>5</td><td>4601.940</td><td>ns/op</td></tr><tr><td>VirtualMemoryReadBenchmark.testIntLegacy</td><td>avgt</td><td>5</td><td>7064.822</td><td>ns/op</td></tr></tbody></table><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="32-bit-write"></a>32-Bit Write<a class="hash-link" href="#32-bit-write" title="Direct link to heading">#</a></h3><table><thead><tr><th>Benchmark</th><th>Mode</th><th>Cnt</th><th>Score</th><th>Units</th></tr></thead><tbody><tr><td>VirtualMemoryBenchmark.testPutIntContiguous</td><td>avgt</td><td>5</td><td>5270.264</td><td>ns/op</td></tr><tr><td>VirtualMemoryBenchmark.testPutIntLegacy</td><td>avgt</td><td>5</td><td>5692.148</td><td>ns/op</td></tr></tbody></table><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="64-bit-read"></a>64-bit Read<a class="hash-link" href="#64-bit-read" title="Direct link to heading">#</a></h3><table><thead><tr><th>Benchmark</th><th>Mode</th><th>Cnt</th><th>Score</th><th>Units</th></tr></thead><tbody><tr><td>VirtualMemoryLongReadBenchmark.testLongContiguous</td><td>avgt</td><td>5</td><td>4088.338</td><td>ns/op</td></tr><tr><td>VirtualMemoryLongReadBenchmark.testLongLegacy</td><td>avgt</td><td>5</td><td>5022.875</td><td>ns/op</td></tr></tbody></table><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="64-bit-write"></a>64-bit Write<a class="hash-link" href="#64-bit-write" title="Direct link to heading">#</a></h3><table><thead><tr><th>Benchmark</th><th>Mode</th><th>Cnt</th><th>Score</th><th>Units</th></tr></thead><tbody><tr><td>VirtualMemoryLongWriteBenchmark.testPutLongContiguous</td><td>avgt</td><td>5</td><td>4413.181</td><td>ns/op</td></tr><tr><td>VirtualMemoryLongWriteBenchmark.testPutLongLegacy</td><td>avgt</td><td>5</td><td>6976.593</td><td>ns/op</td></tr></tbody></table><p>And here are the results for strings, which represent 100 reads/writes:</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="string-read"></a>String Read<a class="hash-link" href="#string-read" title="Direct link to heading">#</a></h3><table><thead><tr><th>Benchmark</th><th>Mode</th><th>Cnt</th><th>Score</th><th>Units</th></tr></thead><tbody><tr><td>VirtualMemoryStrReadBenchmark.testGetStrContiguous</td><td>avgt</td><td>5</td><td>300.346</td><td>ns/op</td></tr><tr><td>VirtualMemoryStrReadBenchmark.testGetStrLegacy</td><td>avgt</td><td>5</td><td>525.775</td><td>ns/op</td></tr><tr><td>VirtualMemoryStrWriteBenchmark.testPutStrContiguous</td><td>avgt</td><td>5</td><td>2.019</td><td>ns/op</td></tr><tr><td>VirtualMemoryStrWriteBenchmark.testPutStrLegacy</td><td>avgt</td><td>5</td><td>3.646</td><td>ns/op</td></tr></tbody></table><p>For those of you that are more graphicly-inclined:</p><p><img alt="Benchmark showing the relative performance of primitive types" src="/assets/images/primitives-20aae46c1b4abd47c5142c524ebbc624.png"></p><p><img alt="Benchmark showing the relative performance of string types" src="/assets/images/strings-c15a13ab0f60a61ddfcc943ad4050780.png"></p><p>Again, we think these numbers speak for themselves, but we&#x27;re always happy to
hear from you, our users and community, about what you think.</p></div><footer class="row margin-vert--lg"><div class="col"><strong>Tags:</strong><a class="margin-horiz--sm" href="/blog/tags/engineering">engineering</a><a class="margin-horiz--sm" href="/blog/tags/performance">performance</a><a class="margin-horiz--sm" href="/blog/tags/architecture">architecture</a></div></footer></article><div></div><div class="margin-vert--xl"><nav class="pagination-nav" aria-label="Blog post page navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/blog/2020/08/25/fast-iot-stack-with-questdb-mqtt"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">Â« A Lightweight, blazing fast stack for your IoT application</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/blog/2020/08/06/my-journey-writing-questdb"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">My journey making QuestDB Â»</div></a></div></nav></div></main></div></div><div class="root_0lLS"><div class="cards_xeZk"><div class="root_R798 skinPrimary_JHOH"><svg width="76" height="76" viewBox="0 0 76 76" fill="none" xmlns="http://www.w3.org/2000/svg"><circle cx="38" cy="38" r="38" fill="#1E1F27"></circle><path d="M56.99 18.792a.817.817 0 00-.117-.303c-.01-.02-.02-.05-.03-.069-.01-.02-.029-.029-.048-.049a.912.912 0 00-.137-.136l-.117-.088c-.02-.01-.03-.03-.05-.04-.029-.01-.068-.029-.107-.039a.85.85 0 00-.146-.049 1.075 1.075 0 00-.176-.019h-.147a1.15 1.15 0 00-.196.049c-.029.01-.068.01-.097.02L12.59 36.67a.979.979 0 00-.509 1.29c.098.216.264.401.48.5l16.07 7.556v15.025c0 .537.44.977.978.977a.964.964 0 00.831-.469l6.794-11.046 10.499 5.533a.974.974 0 001.408-.655l7.84-36.2v-.058c.01-.058.01-.107.019-.156 0-.059 0-.117-.01-.176zM29.413 44.208L15.376 37.6l36.326-15.68-22.289 22.288zm1.174 13.363V47.004l4.917 2.59-4.917 7.977zm16.92-3.87l-9.237-4.86-1.662-1.026-.068.118-5.289-2.786 23.1-23.12L47.508 53.7z" fill="#fff"></path></svg><h3 class="title_BHe0">ë¬¸ìíê¸°</h3><p class="description_Bwvi">ì´ë©ì¼ì ìë ¥íìë©´ ìê°ìë£ë¥¼ ë³´ë´ëë¦½ëë¤.</p><div class="content_gAr2"><form class="root_teCd"><div><div class="inputs_0wQ8"><input type="email" class="input_cjQx input_a6pP" name="email" required="" pattern="^[a-zA-Z0-9.!#$%&amp;&#x27;*+/=?^_`{|}~-]+@[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(?:\.[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)+$" placeholder="Email address" title="Email address should be valid"><button class="submit_poRs button_f7Ff button--tertiary_vtfp button--uppercase_ESEN" type="submit">ë³´ë´ê¸°</button></div></div></form></div></div></div></div></div><footer class="root_JnvJ"><div class="content_-gfC center_S24y"><img alt="QuestDB logo" class="logo_JrwJ" src="/img/navbar/tp_brand.png" width="108" height="27"><div class="tagline_T1tH"><p>ì¸íë¼ê´ë¦¬ë¶í° ìë¹ì¤ì´ìê¹ì§ í´ë¼ì°ëíê²½ì ìµì íë í´ë¼ì°ë ë¤ì´í°ë¸ íë«í¼</p></div><div class="links_1SgP"></div></div><div class="border_PW0V"><div class="bottom_wPs3 center_S24y">Copyright Â© 2023 Gitple. All rights are reserved.</div></div></footer></div>
<script src="/assets/js/main.3e047ba9.js" defer="defer"></script>
</body>
</html>