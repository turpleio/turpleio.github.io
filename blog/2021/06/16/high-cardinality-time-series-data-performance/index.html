<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=3">
<meta httpequiv="x-ua-compatible" content="ie=edge">
<meta property="og:type" content="website">
<meta name="author" content="turpleio">
<meta name="generator" content="Docusaurus v2.0.0-alpha.75">
<link href="https://www.googletagmanager.com" rel="dns-prefetch">
<link href="https://www.google-analytics.com" rel="dns-prefetch">
<link rel="icon" href="/favicon.png">
<link rel="apple-touch-icon" href="/img/icons/apple-180x180.png" sizes="180x180">
<meta name="msapplication-config" content="/browserconfig.xml">
<link rel="sitemap" type="application/xml" href="/sitemap.xml">
<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=GTM-PVR7M2G"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","GTM-PVR7M2G",{anonymize_ip:!0})</script>
<link rel="search" type="application/opensearchdescription+xml" title="Turple: Cloud Native Platform" href="/opensearch.xml">
<link rel="manifest" href="/manifest.webmanifest">
<meta name="theme-color" content="#d14671">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#21222c">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Turple: Cloud Native Platform Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Turple: Cloud Native Platform Blog Atom Feed"><title data-react-helmet="true">How databases handle 10 million devices in high-cardinality benchmarks | Turple: Cloud Native Platform</title><meta data-react-helmet="true" property="og:title" content="How databases handle 10 million devices in high-cardinality benchmarks | Turple: Cloud Native Platform"><meta data-react-helmet="true" name="description" content="Most open source time series databases struggle with high-cardinality time series data. Learn more about high-cardinality and how to benchmark database performance with this type of data."><meta data-react-helmet="true" name="twitter:description" content="Most open source time series databases struggle with high-cardinality time series data. Learn more about high-cardinality and how to benchmark database performance with this type of data."><meta data-react-helmet="true" property="og:description" content="Most open source time series databases struggle with high-cardinality time series data. Learn more about high-cardinality and how to benchmark database performance with this type of data."><meta data-react-helmet="true" name="twitter:title" content="How databases handle 10 million devices in high-cardinality benchmarks | Turple: Cloud Native Platform"><meta data-react-helmet="true" name="twitter:image:alt" content="Image for &quot;How databases handle 10 million devices in high-cardinality benchmarks | Turple: Cloud Native Platform&quot;"><meta data-react-helmet="true" name="keywords" content="clickhouse,influxdb,timescaledb,tsbs,benchmark,timeseries,database"><meta data-react-helmet="true" property="og:image" content="https://turpleio.github.io/img/blog/2021-06-16/banner.png"><meta data-react-helmet="true" name="twitter:image" content="https://turpleio.github.io/img/blog/2021-06-16/banner.png"><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><link rel="stylesheet" href="/assets/css/styles.4f6557e4.css">
</head>
<body itemscope itemtype="http://schema.org/Organization">
<meta itemprop="name" content="Turple: Cloud Native Platform">
<meta itemprop="description" content="Turple is a cloud native platform which can help you build and operate your services on cloud.">
<meta itemprop="url" content="https://turpleio.github.io">
<meta itemprop="logo" content="https://turpleio.github.io/img/favicon.png">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"dark")}()</script><div id="__docusaurus">
<nav class="navbar navbar_wBc8 navbar--light"><div class="navbar__inner inner_Y8Z6"><div class="navbar__items"><div aria-label="Navigation bar toggle" class="navbar__toggle" role="button" tabindex="0"><svg xmlns="http://www.w3.org/2000/svg" width="30" height="30" viewBox="0 0 30 30" role="img" focusable="false"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></div><a class="navbar__brand brand_AtiA" href="/">QuestDB</a></div><div class="navbar__items navbar__items--right"></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div><div class="navbar-sidebar"><div class="navbar-sidebar__brand"><a class="navbar__brand brand_AtiA" href="/">QuestDB</a></div><div class="navbar-sidebar__items"><div class="menu"><ul class="menu__list"></ul></div></div></div></nav><div class="wrapper_DIJ0 blog-wrapper"><div class="container margin-vert--lg"><div class="row"><div class="col col--3"><div class="sidebar_q+wC thin-scrollbar"><h3 class="sidebarItemTitle_9G5K">Recent posts</h3><ul class="sidebarItemList_6T4b"><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/2022/12/19/merry-questmas-gifts-2023">Merry Questmas! Here are your gifts for 2023...</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/2022/12/13/using-prometheus-loki-grafana-monitor-questdb-kubernetes">Using Prometheus, Loki, and Grafana to monitor QuestDB in Kubernetes</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/2022/11/30/full-table-scan-are-fast">Listen to Your CPU - Full-table Scans Are Fast</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/2022/11/25/questdb-6.6.1-dynamic-commits">QuestDB 6.6.1 - Dynamic Commits</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/2022/11/23/sql-extensions-time-series-data-questdb-part-ii">SQL Extensions for Time Series Data in QuestDB - Part II</a></li></ul></div></div><main class="col col--7"><article><header><h1 class="title_KBQu">How databases handle 10 million devices in high-cardinality benchmarks</h1><time datetime="2021-06-16T00:00:00.000Z" class="date_A31P">June 16, 2021 · 10 min read</time><div class="avatar margin-vert--md"><a href="https://github.com/bluestreak01" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img src="https://avatars.githubusercontent.com/bluestreak01" alt="Vlad Ilyushchenko"></a><div class="avatar__intro"><h4 class="avatar__name"><a href="https://github.com/bluestreak01" target="_blank" rel="noopener noreferrer">Vlad Ilyushchenko</a></h4><small class="avatar__subtitle">QuestDB Team</small></div></div></header><div class="markdown"><p>If you&#x27;re working with large amounts of data, you&#x27;ve likely heard about
high-cardinality or ran into issues relating to it. It might sound like an
intimidating topic if you&#x27;re unfamiliar with it, but this article explains what
cardinality is and why it crops up often with databases of all types. IoT and
monitoring are use cases where high-cardinality is more likely to be a concern.
Still, a solid understanding of this concept helps when planning general-purpose
database schemas and understanding common factors that can influence database
performance.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="what-is-high-cardinality-data"></a>What is high-cardinality data?<a class="hash-link" href="#what-is-high-cardinality-data" title="Direct link to heading">#</a></h2><p>Cardinality typically refers to the number of elements in a set&#x27;s size. In the
context of a time series database (TSDB), rows will usually have columns that
categorize the data and act like tags. Assume you have 1000 IoT devices in 20
locations, they&#x27;re running one of 5 firmware versions, and report input from 5
types of sensor per device. The cardinality of this set is 500,000 (<strong>1000 x 20
x 5 x 5</strong>). This can quickly get unmanageable in some cases, as even adding and
tracking a new firmware version for the devices would increase the set to
600,000 (<strong>1000 x 20 x 6 x 5</strong>).</p><p>In these scenarios, experience shows that we will want to eventually get
insights on more kinds of information about the devices, such as application
errors, device state, metadata, configuration and so on. With each new tag or
category we add to our data set, cardinality grows exponentially. In a database,
high-cardinality boils down to the following two conditions:</p><ol><li>a table has many indexed columns</li><li>each indexed column contains many unique values</li></ol><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="how-can-i-measure-database-performance-using-high-cardinality-data"></a>How can I measure database performance using high-cardinality data?<a class="hash-link" href="#how-can-i-measure-database-performance-using-high-cardinality-data" title="Direct link to heading">#</a></h2><p>A popular way of measuring the throughput of time series databases is to use the
Time Series Benchmark Suite, a collection of Go programs that generate metrics
from multiple simulated systems. For measuring the performance of QuestDB, we
create data in InfluxDB line protocol format, which consists of ten &#x27;tags&#x27; and
ten &#x27;measurements&#x27; per row.</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI bash"><div tabindex="0" class="prism-code language-bash codeBlock_rtdJ thin-scrollbar"><div class="codeBlockLines_1zSZ" style="color:#f8f8f2;background-color:#262833"><div class="token-line" style="color:#f8f8f2"><span class="token plain">tsbs_generate_data --scale</span><span class="token operator" style="color:#ff79c6">=</span><span class="token number" style="color:#50fa7b">100</span><span class="token plain"> </span><span class="token punctuation" style="color:#f8f8f2">\</span><span class="token plain"></span></div><div class="token-line" style="color:#f8f8f2"><span class="token plain">  --timestamp-start</span><span class="token operator" style="color:#ff79c6">=</span><span class="token string" style="color:#f1fa8c">&quot;2016-01-01T00:00:00Z&quot;</span><span class="token plain"> --timestamp-end</span><span class="token operator" style="color:#ff79c6">=</span><span class="token string" style="color:#f1fa8c">&quot;2016-01-15T00:00:00Z&quot;</span><span class="token plain"> </span><span class="token punctuation" style="color:#f8f8f2">\</span><span class="token plain"></span></div><div class="token-line" style="color:#f8f8f2"><span class="token plain">  --use-case</span><span class="token operator" style="color:#ff79c6">=</span><span class="token string" style="color:#f1fa8c">&quot;cpu-only&quot;</span><span class="token plain"> --seed</span><span class="token operator" style="color:#ff79c6">=</span><span class="token number" style="color:#50fa7b">123</span><span class="token plain"> --log-interval</span><span class="token operator" style="color:#ff79c6">=</span><span class="token string" style="color:#f1fa8c">&quot;10s&quot;</span><span class="token plain"> --format</span><span class="token operator" style="color:#ff79c6">=</span><span class="token string" style="color:#f1fa8c">&quot;influx&quot;</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB">Copy</button></div></div><p>If we want to influence cardinality, we can use the <code>scale</code> flag, which provides
a value for the number of unique devices we want the test data set to contain.
As the number of devices increases, so does the number of unique identifiers
values per data set, and we can control cardinality directly. Here&#x27;s some
example output from the Time Series Benchmark Suite test data with three
different devices:</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI csv"><div tabindex="0" class="prism-code language-csv codeBlock_rtdJ thin-scrollbar"><div class="codeBlockLines_1zSZ" style="color:#f8f8f2;background-color:#262833"><div class="token-line" style="color:#f8f8f2"><span class="token plain">&quot;hostname&quot;,&quot;region&quot;,&quot;datacenter&quot;,&quot;rack&quot;,&quot;os&quot;,&quot;arch&quot;,&quot;team&quot;,&quot;service&quot;,&quot;service_version&quot;,&quot;service_environment&quot;,&quot;usage_user&quot;,&quot;usage_system&quot;,&quot;usage_idle&quot;,&quot;usage_nice&quot;,&quot;usage_iowait&quot;,&quot;usage_irq&quot;,&quot;usage_softirq&quot;,&quot;usage_steal&quot;,&quot;usage_guest&quot;,&quot;usage_guest_nice&quot;,&quot;timestamp&quot;</span></div><div class="token-line" style="color:#f8f8f2"><span class="token plain">&quot;host_0&quot;,&quot;eu-central-1&quot;,&quot;eu-central-1a&quot;,&quot;6&quot;,&quot;Ubuntu15.10&quot;,&quot;x86&quot;,&quot;SF&quot;,&quot;19&quot;,&quot;1&quot;,&quot;test&quot;,58,2,24,61,22,63,6,44,80,38,&quot;2016-01-01T00:00:00.000000Z&quot;</span></div><div class="token-line" style="color:#f8f8f2"><span class="token plain">&quot;host_1&quot;,&quot;us-west-1&quot;,&quot;us-west-1a&quot;,&quot;41&quot;,&quot;Ubuntu15.10&quot;,&quot;x64&quot;,&quot;NYC&quot;,&quot;9&quot;,&quot;1&quot;,&quot;staging&quot;,84,11,53,87,29,20,54,77,53,74,&quot;2016-01-01T00:00:00.000000Z&quot;</span></div><div class="token-line" style="color:#f8f8f2"><span class="token plain">&quot;host_2&quot;,&quot;sa-east-1&quot;,&quot;sa-east-1a&quot;,&quot;89&quot;,&quot;Ubuntu16.04LTS&quot;,&quot;x86&quot;,&quot;LON&quot;,&quot;13&quot;,&quot;0&quot;,&quot;staging&quot;,29,48,5,63,17,52,60,49,93,1,&quot;2016-01-01T00:00:00.000000Z&quot;</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB">Copy</button></div></div><p>The table that we create on ingestion then stores <strong>tags</strong> as <code>symbol</code> types.
This <code>symbol</code> type is used to efficiently store repeating string values so that
similar records may be grouped together. Columns of this type are indexed so
that queries across tables by symbol are faster and more efficient to execute.
The <strong>unique</strong> values per <code>symbol</code> column in the benchmark test data are:</p><ul><li>hostname = <code>scale_val</code></li><li>region = 3</li><li>datacenter = 3</li><li>rack = 3</li><li>os = 2</li><li>arch = 2</li><li>team = 3</li><li>service = 3</li><li>service_version = 2</li><li>service_environment = 2</li></ul><p>This means we can calculate the cardinality of our test data as:</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI bash"><div tabindex="0" class="prism-code language-bash codeBlock_rtdJ thin-scrollbar"><div class="codeBlockLines_1zSZ" style="color:#f8f8f2;background-color:#262833"><div class="token-line" style="color:#f8f8f2"><span class="token plain">scale_val x </span><span class="token number" style="color:#50fa7b">3</span><span class="token plain"> x </span><span class="token number" style="color:#50fa7b">3</span><span class="token plain"> x </span><span class="token number" style="color:#50fa7b">3</span><span class="token plain"> x </span><span class="token number" style="color:#50fa7b">2</span><span class="token plain"> x </span><span class="token number" style="color:#50fa7b">2</span><span class="token plain"> x </span><span class="token number" style="color:#50fa7b">3</span><span class="token plain"> x </span><span class="token number" style="color:#50fa7b">3</span><span class="token plain"> x </span><span class="token number" style="color:#50fa7b">2</span><span class="token plain"> x </span><span class="token number" style="color:#50fa7b">2</span><span class="token plain"></span></div><div class="token-line" style="color:#f8f8f2"><span class="token plain"></span><span class="token comment" style="color:#6272a4"># or</span><span class="token plain"></span></div><div class="token-line" style="color:#f8f8f2"><span class="token plain">scale_val x </span><span class="token number" style="color:#50fa7b">3888</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB">Copy</button></div></div><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="exploring-high-cardinality-in-a-time-series-database-benchmark"></a>Exploring high-cardinality in a time series database benchmark<a class="hash-link" href="#exploring-high-cardinality-in-a-time-series-database-benchmark" title="Direct link to heading">#</a></h2><p>When we released QuestDB version 6.0,
<a href="/blog/2021/05/10/questdb-release-6-0-tsbs-benchmark">we included benchmark results</a>
that tested the performance of our new ingestion subsystem, but we didn&#x27;t touch
on the subject of cardinality at all. We wanted to explore this topic in more
detail to see how QuestDB can handle different degrees of cardinality. We also
thought this would be interesting to share with readers as high-cardinality is a
well-known topic for developers and users of databases.</p><p>The tests we ran for our previous benchmarks all used a scale of 4000, meaning
we had a cardinality of 15,552,000 for all systems. For this benchmark, we
created multiple data sets with the following scale and the resulting
cardinality:</p><table><thead><tr><th>scale</th><th>cardinality</th></tr></thead><tbody><tr><td><code>100</code></td><td>388,800</td></tr><tr><td><code>4000</code></td><td>15,552,000</td></tr><tr><td><code>100000</code></td><td>388,800,000</td></tr><tr><td><code>1000000</code></td><td>3,888,000,000</td></tr><tr><td><code>10000000</code></td><td>38,880,000,000</td></tr></tbody></table><p>We also wanted to see what happens when we rerun the tests and provide more
threads (workers) to each system to observe how a database scales with
cardinality based on how much work it can perform in parallel. For that reason,
we tested each database with the scale values the table above using 4, 6, and 16
threads on two different hosts which have the following specifications:</p><ol><li>AWS EC2 m5.8xlarge instance, Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz</li><li>AMD Ryzen 3970X 32-Core, GIGABYTE NVME HD</li></ol><p>The following chart compares ingestion performance from lowest to highest
cardinality running on the AWS EC2 instance with four threads:</p><figure><img alt="High-cardinality time series benchmark results showing QuestDB outperforming ClickHouse, TimescaleDB and InfluxDB when using six workers" class="image_Pw1y margin_Rc0b shadow_7z-4 title_f-p+" height="415" src="/img/blog/2021-06-16/maximum-throughput-by-device-4-threads.png" width="650"><figcaption class="caption_-tGK">TSBS results using 4 threads on AWS EC2 m5.8xlarge</figcaption></figure><p>Using a dataset with low cardinality of 100 devices, we hit maximum ingestion
throughput of 904k rows/sec, with ClickHouse performing closest at 548k
rows/sec. However, when increasing cardinality to 10 million devices, QuestDB
sustains 640k rows/sec, and ClickHouse ingestion decreases at a similar rate
relative to the device count with 345k rows/sec.</p><p>The other systems under test struggled with higher unique device count, with
InfluxDB ingestion dropping to 38k rows/sec and TimescaleDB at 50k rows/sec with
10M devices. We reran the benchmark suite on the same AWS EC2 instance and
increased the worker count (16 threads) to the systems under test:</p><figure><img alt="High-cardinality time series benchmark results showing QuestDB outperforming ClickHouse, TimescaleDB and InfluxDB when using sixteen workers" class="image_Pw1y margin_Rc0b shadow_7z-4 title_f-p+" height="415" src="/img/blog/2021-06-16/maximum-throughput-by-device-16-threads.png" width="650"><figcaption class="caption_-tGK">TSBS results using 16 threads on AWS EC2 m5.8xlarge</figcaption></figure><p>QuestDB showed a mostly constant ingestion rate of 815k rows/sec with all
degrees of cardinality. ClickHouse could ingest 900k rows/sec but requires four
times as many workers as QuestDB to achieve this rate. ClickHouse ingestion
drops to 409k rows/sec on the largest data set. There was no significant change
in performance between four and sixteen workers for TimescaleDB. InfluxDB
struggled the most, failing to finish successfully on the largest data set.</p><p>We ran the same benchmarks on a separate system using the AMD Ryzen 3970X, using
4, 6, and 16 threads to see if we could observe any changes in ingestion rates:</p><figure><img alt="High-cardinality time series benchmark results showing QuestDB, ClickHouse, TimescaleDB and InfluxDB when using six workers" class="image_Pw1y margin_Rc0b shadow_7z-4 title_f-p+" height="415" src="/img/blog/2021-06-16/maximum-throughput-by-device-scale-6-threads-ryzen.png" width="650"><figcaption class="caption_-tGK">TSBS results using 6 threads on AMD Ryzen 3970X</figcaption></figure><p>QuestDB hits maximum throughput with 1M devices during this run, with other
systems performing better than on the AWS instance. We can assume that
TimescaleDB is disk-bound as results change dramatically based on the difference
between the tests run on the EC2 instance. QuestDB performance peaks when using
four workers and slows down at 16 workers.</p><p>One key observation is that QuestDB handles high-cardinality better with more
threads. Conversely, when cardinality is low, fewer workers lead to an overall
higher maximum throughput and a steeper drop in ingestion rates when going from
1M devices to 10M. The reason for lower maximum throughput when adding more
workers is due to increased thread contention:</p><figure><img alt="High-cardinality time series benchmark results showing ingestion performance of QuestDB when using four versus 16 threads" class="image_Pw1y margin_Rc0b shadow_7z-4 title_f-p+" height="415" src="/img/blog/2021-06-16/questdb-max-throughput-by-number-threads.png" width="650"><figcaption class="caption_-tGK">TSBS results for QuestDB using 4 and 16 threads on AWS EC2 m5.8xlarge</figcaption></figure><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="why-questdb-can-easily-ingest-time-series-data-with-high-cardinality"></a>Why QuestDB can easily ingest time series data with high-cardinality<a class="hash-link" href="#why-questdb-can-easily-ingest-time-series-data-with-high-cardinality" title="Direct link to heading">#</a></h2><p>There are several reasons why QuestDB can quickly ingest data of this type; one
factor is the data model that we use to store and index data. High-cardinality
data has not been a pain point for our users due to our choices when designing
the system architecture from day one. This storage model was chosen for
architectural simplicity and quick read and write operations.</p><p>The main reason why QuestDB can handle high-cardinality data is that we
massively parallelize hashmap operations on indexed columns. In addition, we use
SIMD to do a lot of heavy lifting across the entire SQL engine, which means that
we can execute procedures relating to indexes and hashmap lookup in parallel
where possible.</p><p>Users who have migrated from other time-series databases told us that degraded
performance from high-cardinality data manifests with most systems early, but
their threshold for usability is about 300K. After running the benchmark with
high-cardinality, we were pleased with our system stability with up to 10
million devices without a significant performance drop.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="configuring-parameters-to-optimize-ingestion-on-high-cardinality-data"></a>Configuring parameters to optimize ingestion on high-cardinality data<a class="hash-link" href="#configuring-parameters-to-optimize-ingestion-on-high-cardinality-data" title="Direct link to heading">#</a></h2><p>The ingestion subsystem that
<a href="https://github.com/questdb/questdb/releases" target="_blank" rel="noopener noreferrer">we shipped in version 6.0</a>
introduces parameters that users may configure server-wide or specific to a
table. These parameters specify how long to keep incoming data in memory and how
often to merge and commit incoming data to disk. The two parameters that are
relevant for high-cardinality data ingestion are commit lag and the maximum
uncommitted rows.</p><p>Lag refers to the expected maximum lateness of incoming data relative to the
newest timestamp value. When records arrive at the database with timestamp
values out-of-order by the value specified in the commit lag, sort and merge
commits are executed. Additionally, the maximum uncommitted rows can be set on a
table which is a threshold for the maximum number of rows to keep in memory
before sorting and committing data. The benefit of these parameters is we can
minimize the frequency of commits depending on the characteristics of the
incoming data:</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI questdb-sql"><div tabindex="0" class="prism-code language-questdb-sql codeBlock_rtdJ thin-scrollbar"><div class="codeBlockLines_1zSZ" style="color:#f8f8f2;background-color:#262833"><div class="token-line" style="color:#f8f8f2"><span class="token plain">alter table cpu set param commitLag=50us;</span></div><div class="token-line" style="color:#f8f8f2"><span class="token plain">alter table cpu set param maxUncommittedRows=10000000;</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB">Copy</button></div></div><p>If we take a look at the type of data that we are generating in the Time Series
Benchmark Suite, we can see that for 10M devices, the duration of the data set
is relatively short (defined by the timestamp <code>--timestamp-start</code> and
<code>--timestamp-end</code> flags):</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI bash"><div tabindex="0" class="prism-code language-bash codeBlock_rtdJ thin-scrollbar"><div class="codeBlockLines_1zSZ" style="color:#f8f8f2;background-color:#262833"><div class="token-line" style="color:#f8f8f2"><span class="token plain">tsbs_generate_data --scale</span><span class="token operator" style="color:#ff79c6">=</span><span class="token number" style="color:#50fa7b">10000000</span><span class="token plain"> </span><span class="token punctuation" style="color:#f8f8f2">\</span><span class="token plain"></span></div><div class="token-line" style="color:#f8f8f2"><span class="token plain">  --timestamp-start</span><span class="token operator" style="color:#ff79c6">=</span><span class="token string" style="color:#f1fa8c">&quot;2016-01-01T00:00:00Z&quot;</span><span class="token plain"> --timestamp-end</span><span class="token operator" style="color:#ff79c6">=</span><span class="token string" style="color:#f1fa8c">&quot;2016-01-01T0:00:36Z&quot;</span><span class="token plain"></span></div><div class="token-line" style="color:#f8f8f2"><span class="token plain">  --log-interval</span><span class="token operator" style="color:#ff79c6">=</span><span class="token string" style="color:#f1fa8c">&quot;10s&quot;</span><span class="token plain"> --format</span><span class="token operator" style="color:#ff79c6">=</span><span class="token string" style="color:#f1fa8c">&quot;influx&quot;</span><span class="token plain"> </span><span class="token punctuation" style="color:#f8f8f2">\</span><span class="token plain"></span></div><div class="token-line" style="color:#f8f8f2"><span class="token plain">  --use-case</span><span class="token operator" style="color:#ff79c6">=</span><span class="token string" style="color:#f1fa8c">&quot;cpu-only&quot;</span><span class="token plain"> --seed</span><span class="token operator" style="color:#ff79c6">=</span><span class="token number" style="color:#50fa7b">123</span><span class="token plain"> </span><span class="token operator" style="color:#ff79c6">&gt;</span><span class="token plain"> /tmp/cpu-10000000</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB">Copy</button></div></div><p>This command generates a data set of 36M rows and spans only 36 seconds of
simulated activity. With throughput at this degree, the commit lag can be a much
smaller value, such as 50 or 100 microseconds, and the maximum uncommitted rows
can be around 10M. The explanation behind these values is that we expect a much
narrower band of the lateness of records in terms of out-of-order data, and we
have an upper-bounds of 10M records in memory before a commit occurs.</p><p>Planning the schema of a table for high-cardinality data can also have a
significant performance impact. For example, when creating a table, we can
designate resources for indexed columns to know how many unique values the
symbol column will contain, and done via capacity as follows:</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI questdb-sql"><div tabindex="0" class="prism-code language-questdb-sql codeBlock_rtdJ thin-scrollbar"><div class="codeBlockLines_1zSZ" style="color:#f8f8f2;background-color:#262833"><div class="token-line" style="color:#f8f8f2"><span class="token plain">create table cpu (</span></div><div class="token-line" style="color:#f8f8f2"><span class="token plain">  hostname symbol capacity 20000000,</span></div><div class="token-line" style="color:#f8f8f2"><span class="token plain">  region symbol,</span></div><div class="token-line" style="color:#f8f8f2"><span class="token plain">  ...</span></div><div class="token-line" style="color:#f8f8f2"><span class="token plain">) timestamp(timestamp) partition by DAY;</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB">Copy</button></div></div><p>In this case, we&#x27;re setting a capacity of 20M for the <code>hostname</code> column, which
we know will contain 10M values. It&#x27;s generally a good idea to specify the
capacity of an indexed column at about twice the expected unique values if the
data are out-of-order. High RAM usage is associated with using a large capacity
on indexed symbols with high-cardinality data as these values sit on the memory
heap.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="next-up"></a>Next up<a class="hash-link" href="#next-up" title="Direct link to heading">#</a></h2><p>This article shows how high-cardinality can quickly emerge in time series data
in industrial IoT, monitoring, application data and many other scenarios. If you
have have feedback or questions about this article, feel free ask in our
<a href="https://slack.questdb.io/" target="_blank" rel="noopener noreferrer">Slack Community</a> or browse the
<a href="https://github.com/questdb/questdb" target="_blank" rel="noopener noreferrer">project on GitHub</a> where we welcome
contributions of all kinds.</p></div><footer class="row margin-vert--lg"><div class="col"><strong>Tags:</strong><a class="margin-horiz--sm" href="/blog/tags/benchmark">benchmark</a><a class="margin-horiz--sm" href="/blog/tags/clickhouse">clickhouse</a><a class="margin-horiz--sm" href="/blog/tags/timescaledb">timescaledb</a><a class="margin-horiz--sm" href="/blog/tags/influxdb">influxdb</a><a class="margin-horiz--sm" href="/blog/tags/cardinality">cardinality</a><a class="margin-horiz--sm" href="/blog/tags/telegraf">telegraf</a></div></footer></article><div></div><div class="margin-vert--xl"><nav class="pagination-nav" aria-label="Blog post page navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/blog/2021/06/18/tracking-multiple-cryptocurrency-exchanges"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">« Tracking multiple cryptocurrency exchanges using a time series database</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/blog/2021/05/10/questdb-release-6-0-tsbs-benchmark"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">How we achieved write speeds of 1.4 million rows per second »</div></a></div></nav></div></main></div></div><div class="root_0lLS"><div class="cards_xeZk"><div class="root_R798 skinPrimary_JHOH"><svg width="76" height="76" viewBox="0 0 76 76" fill="none" xmlns="http://www.w3.org/2000/svg"><circle cx="38" cy="38" r="38" fill="#1E1F27"></circle><path d="M56.99 18.792a.817.817 0 00-.117-.303c-.01-.02-.02-.05-.03-.069-.01-.02-.029-.029-.048-.049a.912.912 0 00-.137-.136l-.117-.088c-.02-.01-.03-.03-.05-.04-.029-.01-.068-.029-.107-.039a.85.85 0 00-.146-.049 1.075 1.075 0 00-.176-.019h-.147a1.15 1.15 0 00-.196.049c-.029.01-.068.01-.097.02L12.59 36.67a.979.979 0 00-.509 1.29c.098.216.264.401.48.5l16.07 7.556v15.025c0 .537.44.977.978.977a.964.964 0 00.831-.469l6.794-11.046 10.499 5.533a.974.974 0 001.408-.655l7.84-36.2v-.058c.01-.058.01-.107.019-.156 0-.059 0-.117-.01-.176zM29.413 44.208L15.376 37.6l36.326-15.68-22.289 22.288zm1.174 13.363V47.004l4.917 2.59-4.917 7.977zm16.92-3.87l-9.237-4.86-1.662-1.026-.068.118-5.289-2.786 23.1-23.12L47.508 53.7z" fill="#fff"></path></svg><h3 class="title_BHe0">문의하기</h3><p class="description_Bwvi">이메일을 입력하시면 소개자료를 보내드립니다.</p><div class="content_gAr2"><form class="root_teCd"><div><div class="inputs_0wQ8"><input type="email" class="input_cjQx input_a6pP" name="email" required="" pattern="^[a-zA-Z0-9.!#$%&amp;&#x27;*+/=?^_`{|}~-]+@[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(?:\.[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)+$" placeholder="Email address" title="Email address should be valid"><button class="submit_poRs button_f7Ff button--tertiary_vtfp button--uppercase_ESEN" type="submit">보내기</button></div></div></form></div></div></div></div></div><footer class="root_JnvJ"><div class="content_-gfC center_S24y"><img alt="QuestDB logo" class="logo_JrwJ" src="/img/navbar/tp_brand.png" width="108" height="27"><div class="tagline_T1tH"><p>인프라관리부터 서비스운영까지 클라우드환경에 최적화된 클라우드 네이티브 플랫폼</p></div><div class="links_1SgP"></div></div><div class="border_PW0V"><div class="bottom_wPs3 center_S24y">Copyright © 2023 Gitple. All rights are reserved.</div></div></footer></div>
<script src="/assets/js/main.3e047ba9.js" defer="defer"></script>
</body>
</html>