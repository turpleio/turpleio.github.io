"use strict";(self.webpackChunkquestdb_io=self.webpackChunkquestdb_io||[]).push([[1496],{3905:function(e,t,a){a.d(t,{Zo:function(){return d},kt:function(){return m}});var n=a(67294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function l(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function i(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},o=Object.keys(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var s=n.createContext({}),u=function(e){var t=n.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):l(l({},t),e)),a},d=function(e){var t=u(e.components);return n.createElement(s.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},h=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,o=e.originalType,s=e.parentName,d=i(e,["components","mdxType","originalType","parentName"]),h=u(a),m=r,g=h["".concat(s,".").concat(m)]||h[m]||p[m]||o;return a?n.createElement(g,l(l({ref:t},d),{},{components:a})):n.createElement(g,l({ref:t},d))}));function m(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=a.length,l=new Array(o);l[0]=h;var i={};for(var s in t)hasOwnProperty.call(t,s)&&(i[s]=t[s]);i.originalType=e,i.mdxType="string"==typeof e?e:r,l[1]=i;for(var u=2;u<o;u++)l[u]=a[u];return n.createElement.apply(null,l)}return n.createElement.apply(null,a)}h.displayName="MDXCreateElement"},33337:function(e,t,a){a.r(t),a.d(t,{frontMatter:function(){return s},metadata:function(){return u},toc:function(){return d},default:function(){return h}});var n=a(83117),r=a(80102),o=(a(67294),a(3905)),l=a(46092),i=["components"],s={title:"Re-examining our approach to memory mapping",author:"David G. Simmons",author_title:"QuestDB Team",author_url:"https://github.com/davidgs",author_image_url:"https://avatars.githubusercontent.com/davidgs",description:"What we learned by re-examining our approach to memory mapping. A low level implementation, as close as posibble to the kernel, enabled even greater performance.",keywords:["performance","questdb","database","tutorial"],image:"/img/blog/2020-08-19/banner.jpg",tags:["engineering","performance","architecture"]},u={permalink:"/blog/2020/08/19/memory-mapping-deep-dive",source:"@site/blog/2020-08-19-memory-mapping-deep-dive.md",title:"Re-examining our approach to memory mapping",description:"What we learned by re-examining our approach to memory mapping. A low level implementation, as close as posibble to the kernel, enabled even greater performance.",date:"2020-08-19T00:00:00.000Z",formattedDate:"August 19, 2020",tags:[{label:"engineering",permalink:"/blog/tags/engineering"},{label:"performance",permalink:"/blog/tags/performance"},{label:"architecture",permalink:"/blog/tags/architecture"}],readingTime:10.085,truncated:!0,prevItem:{title:"A Lightweight, blazing fast stack for your IoT application",permalink:"/blog/2020/08/25/fast-iot-stack-with-questdb-mqtt"},nextItem:{title:"My journey making QuestDB",permalink:"/blog/2020/08/06/my-journey-writing-questdb"}},d=[{value:"How to improve time series performance",id:"how-to-improve-time-series-performance",children:[]},{value:"How to store time series data more efficiently",id:"how-to-store-time-series-data-more-efficiently",children:[]},{value:"Can memory-mapped pages be more efficient?",id:"can-memory-mapped-pages-be-more-efficient",children:[]},{value:"One page to rule them all",id:"one-page-to-rule-them-all",children:[]},{value:"How kernels handle pages efficiently",id:"how-kernels-handle-pages-efficiently",children:[]},{value:"How fast can you go with database speed?",id:"how-fast-can-you-go-with-database-speed",children:[]},{value:"Performance benchmark results",id:"performance-benchmark-results",children:[{value:"32-bit Read",id:"32-bit-read",children:[]},{value:"32-Bit Write",id:"32-bit-write",children:[]},{value:"64-bit Read",id:"64-bit-read",children:[]},{value:"64-bit Write",id:"64-bit-write",children:[]},{value:"String Read",id:"string-read",children:[]}]}],p={toc:d};function h(e){var t=e.components,s=(0,r.Z)(e,i);return(0,o.kt)("wrapper",(0,n.Z)({},p,s,{components:t,mdxType:"MDXLayout"}),(0,o.kt)(l.Z,{alt:"Hand holding an analog stopwatch",height:433,src:"/img/blog/2020-08-19/banner.jpg",width:650,mdxType:"Banner"}," ","Photo by",(0,o.kt)("a",{href:"https://unsplash.com/photos/p3Pj7jOYvnM"},"Veri Ivanova")," on"," ",(0,o.kt)("a",{href:"https://unsplash.com"},"Unsplash")," "),(0,o.kt)("p",null,"How does QuestDB get the kind of performance it does, and how are we continuing\nto squeeze another 50-60% out of it? This post will look at a code change we\nthought would create a negative performance impact, which actually brought a\nsubstantial boost in the system's overall performance and demonstrates that we\nare constantly learning more about performance improvements."),(0,o.kt)("p",null,"If you like this content, show it with a star on\n",(0,o.kt)("a",{parentName:"p",href:"https://github.com/questdb/questdb"},"GitHub")," or come say hi in our\n",(0,o.kt)("a",{parentName:"p",href:"https://"},"community Slack")," workspace."),(0,o.kt)("h2",{id:"how-to-improve-time-series-performance"},"How to improve time series performance"),(0,o.kt)("p",null,"QuestDB started out with a single-threaded approach to queries and such. But one\nobvious way to improve performance in a Java application like this is to\nparallelize as much as you can by using multiple threads of execution."),(0,o.kt)("p",null,"I've written multi-threaded applications, and they are not easy to do. It's hard\nto coordinate the work between multiple threads, and to make sure that there are\nno race conditions, collisions, etc."),(0,o.kt)("h2",{id:"how-to-store-time-series-data-more-efficiently"},"How to store time series data more efficiently"),(0,o.kt)("p",null,"So first it's important to understand that QuestDB stores it's data in columnar\nformat. We store each column of data in a file. So for every column of data,\nthere is a file."),(0,o.kt)("p",null,"We then split those columns up into data frames that are independent and can be\ncomputed completely independently of each other."),(0,o.kt)("p",null,"The problem we encountered with this framing scheme was that it was impossible\nto frame variable length data. Data spilled out of the frame, making it\ndifficult to manage."),(0,o.kt)("p",null,"You see, we store fixed length fields with fixed length values, such that\naligning frames to 8 bytes would ensure that all our fixed length data does not\nstraddle frames. Hence all the columns are the same frame width. But strings and\nblobs can't be forced into 8 bytes without making them useless."),(0,o.kt)("p",null,"So we could extract extreme performance out of all the fixed-length values, but\nthese variable-length values dragged the performance back down."),(0,o.kt)("p",null,"Which brings us to pages and how data is referenced in memory."),(0,o.kt)("h2",{id:"can-memory-mapped-pages-be-more-efficient"},"Can memory-mapped pages be more efficient?"),(0,o.kt)("p",null,"QuestDB uses memory-mapped pages to reference data in order to make it really\nfast. If you're dividing up your data into pages, and all data has a fixed\nlength, then it's relatively easy to ensure that you don't have data that spans\nmultiple pages. You just break pages at multiples of 8-bytes and everything will\nfit within page boundaries."),(0,o.kt)("p",null,"When you add variable-length data, suddenly you cannot ensure that everything\nwill line up along page boundaries and you will have the very real possibility\n-- actually a certainty -- that you may have to jump from one page to another\njust to get all the data contained in a frame."),(0,o.kt)("p",null,"This, it turns out, is hugely inefficient. If (data is in frame) then (process\nthat data) else (figure out where the rest of the data is, get that, then\nprocess it all). This kind of if-then-else sprinkled throughout the code is a)\nhard to debug and b) leads to lots of branching, which slows down execution."),(0,o.kt)("p",null,"In order to prevent variable length data from straddling frames we would need to\nhave different frame lengths per column. Furthermore, calculating aligned frame\nlengths for variable length data is non trivial and requires scanning the entire\ndata set which would reversing any performance gains from parallelization."),(0,o.kt)("h2",{id:"one-page-to-rule-them-all"},"One page to rule them all"),(0,o.kt)("p",null,"(Yes, I just made a ",(0,o.kt)("em",{parentName:"p"},"The Highlander"),"\n",(0,o.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Highlander_(film)"},"reference"),")"),(0,o.kt)("p",null,"What if, in order to get around data being on multiple pages, we simply used\n",(0,o.kt)("em",{parentName:"p"},"one"),' page for all of the data? Of course my first question was "Don\'t you at\nsome point reach a limit on the page size?" but Vlad and Patrick assured me\nthere is, indeed, no limit on a page size.'),(0,o.kt)("p",null,'If your page size is bigger than the available memory, the kernel will handle\nswapping pages in and out for you as you try to access different parts of the\npage. So of course I asked "well then, why didn\'t you do this from the\nbeginning?"'),(0,o.kt)("p",null,'Vlad, in his typically self-deprecating style, just said "We didn\'t know. We\nthought we should keep them to a certain size to keep them from growing out of\ncontrol" which, quite frankly, seems like the right answer.'),(0,o.kt)("p",null,"We'd just resize those smaller pages as needed. But as Vlad explained, if you do\nthat then you need to copy the data over to the new, resized page and \"copying\ncan take over your life.\" Databases aren't built to maximize the efficiency of\ndata copying. They are built to maximize the ability to extract value from data.\nCopying data from one page to another isn't extracting value."),(0,o.kt)("p",null,"So they tried just allocating a new page, and jumping from one page to the next\nas needed to find the required data. This cut down on the copying of data, but\nit lead to the problems outlined in the previous section. You never knew which\npage your data was going to be on, and jumping from one page to another was\nhugely inefficient."),(0,o.kt)("p",null,'So they tried having just the one page. One massive page (that you can grow as\nneeded, without copying data around). Vlad, again in his style, said the\nperformance turned out to be "not bad" with this approach. And by "not bad" he\nof course meant about a 60% performance improvement.'),(0,o.kt)("p",null,"When you get into using one single page, of course the total available address\nspace comes into play. But since QuestDB only runs on 64-bit architectures, we\nhave 2^64 address space, which is more than enough."),(0,o.kt)("p",null,"This is where Patrick jumped in to explain that when you have an area of memory\nmapped from a file, when the file grows you remap the new size into memory. The\noperating system does not need to copy anything; the virtual memory model allows\nthe OS to just remap the already mapped pages into the newly mapped memory\nregion. In many cases, the OS may have already reserved the entire address space\nfor you so your new mapping is in the same region as the old, just bigger."),(0,o.kt)("h2",{id:"how-kernels-handle-pages-efficiently"},"How kernels handle pages efficiently"),(0,o.kt)("p",null,"The kernel allocates a full sized address space for your file when you requested\nthe memory-mapped file. And apparently this is true across Linux, macOS and\nWindows. So from that point on, there's really no further copying that needs to\nhappen."),(0,o.kt)("p",null,"Furthermore, the kernel is going to handle paging parts of that file in and out\nof memory as needed. Now, I'm old-school Unix, and page-swapping which lead to\nthrashing was always something we worried about back in the olden days. So I\nasked about it. According to Patrick, this could only happen really if you have\na massive file that you are reading basically randomly at high speed. Other than\nthat, the kernel will handle reading ahead and pre-loading pages as needed in\norder to be as efficient as possible."),(0,o.kt)("p",null,"Kernels, it turns out, are smart. In fact, kernels are basically smarter than\nyou or I will ever hope to be. They've been developed across decades to be\nhugely efficient at doing these things. It's what they do. The kernel will\nmemory map the file into the file cache and even if it needs to move stuff\naround, it can move the logical address and it's still the same underlying\nphysical memory pages."),(0,o.kt)("p",null,"If you think that you can take over caching the data from the OS and do a better\njob of managing the memory space, and the allocation and re-allocation of the\nmemory, you're wrong. Again, this is what the Kernel does, and at some level,\neven if you try to take this job away from the kernel, it is ",(0,o.kt)("em",{parentName:"p"},"still")," doing some\namount of it anyway. So your attempts to take this memory management and\nallocation away from the kernel has done little more than just add another layer\non top of what the kernel is doing anyway. Another layer on top of something is\nbasically never more efficient than the original thing."),(0,o.kt)("p",null,"When you read an offset into a file, you send a buffer to read into, the address\nto start reading at, and the offset into the file. Now, the kernel is going to\ncache all of that for you as you do it, because that's the kernel's job, really.\nBut many database developers then take that, and cache it themselves, with their\nown caching scheme."),(0,o.kt)("h2",{id:"how-fast-can-you-go-with-database-speed"},"How fast can you go with database speed?"),(0,o.kt)("p",null,"When I asked Vlad about this, and how it relates to query speed, he was quite\nexplicit in saying that thinking you (a database developer) can beat the kernel\nis pure folly. Postgres tries this and, according to Vlad, an aggregation over a\nlarge (really large!) dataset can take 5 ",(0,o.kt)("em",{parentName:"p"},"minutes"),", whereas the same aggregation\non QuestDB takes only 60ms. Those aren't typos."),(0,o.kt)("p",null,"To both Patrick and Vlad (and me, for what that's worth), the idea that we, as\ndevelopers, can be better at these operations than the kernel (when really we're\ndoing them ",(0,o.kt)("em",{parentName:"p"},"on top of")," the kernel anyway) is simply ridiculous. If I take an\narmy of researchers and spend a decade of development, then ",(0,o.kt)("em",{parentName:"p"},"maybe")," I can do it\nbetter than the kernel, but during that time guess what? The army of people\nworking on the kernel will have found further improvements and left me behind\nanyway."),(0,o.kt)("p",null,"It comes down to letting the kernel do its job, and us doing ours. And our job\nis to exploit the kernel for every ounce of performance we can get out of it\nwithout trying to do it's job for it."),(0,o.kt)("h2",{id:"performance-benchmark-results"},"Performance benchmark results"),(0,o.kt)("p",null,"When it comes to performance claims, we always try to back them up with actual\nnumbers that can be replicated. You can run these tests yourself, and you can\nalways go and look at the\n",(0,o.kt)("a",{parentName:"p",href:"https://github.com/questdb/questdb/tree/master/benchmarks/src/main/java/org/questdb"},"source code"),"\nfor these tests to see how they are implemented."),(0,o.kt)("p",null,"We think these numbers speak for themselves."),(0,o.kt)("p",null,"These first results are for the primitives and represent 10,000 reads/writes:"),(0,o.kt)("h3",{id:"32-bit-read"},"32-bit Read"),(0,o.kt)("table",null,(0,o.kt)("thead",{parentName:"table"},(0,o.kt)("tr",{parentName:"thead"},(0,o.kt)("th",{parentName:"tr",align:null},"Benchmark"),(0,o.kt)("th",{parentName:"tr",align:null},"Mode"),(0,o.kt)("th",{parentName:"tr",align:null},"Cnt"),(0,o.kt)("th",{parentName:"tr",align:null},"Score"),(0,o.kt)("th",{parentName:"tr",align:null},"Units"))),(0,o.kt)("tbody",{parentName:"table"},(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"VirtualMemoryReadBenchmark.testIntContiguous"),(0,o.kt)("td",{parentName:"tr",align:null},"avgt"),(0,o.kt)("td",{parentName:"tr",align:null},"5"),(0,o.kt)("td",{parentName:"tr",align:null},"4601.940"),(0,o.kt)("td",{parentName:"tr",align:null},"ns/op")),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"VirtualMemoryReadBenchmark.testIntLegacy"),(0,o.kt)("td",{parentName:"tr",align:null},"avgt"),(0,o.kt)("td",{parentName:"tr",align:null},"5"),(0,o.kt)("td",{parentName:"tr",align:null},"7064.822"),(0,o.kt)("td",{parentName:"tr",align:null},"ns/op")))),(0,o.kt)("h3",{id:"32-bit-write"},"32-Bit Write"),(0,o.kt)("table",null,(0,o.kt)("thead",{parentName:"table"},(0,o.kt)("tr",{parentName:"thead"},(0,o.kt)("th",{parentName:"tr",align:null},"Benchmark"),(0,o.kt)("th",{parentName:"tr",align:null},"Mode"),(0,o.kt)("th",{parentName:"tr",align:null},"Cnt"),(0,o.kt)("th",{parentName:"tr",align:null},"Score"),(0,o.kt)("th",{parentName:"tr",align:null},"Units"))),(0,o.kt)("tbody",{parentName:"table"},(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"VirtualMemoryBenchmark.testPutIntContiguous"),(0,o.kt)("td",{parentName:"tr",align:null},"avgt"),(0,o.kt)("td",{parentName:"tr",align:null},"5"),(0,o.kt)("td",{parentName:"tr",align:null},"5270.264"),(0,o.kt)("td",{parentName:"tr",align:null},"ns/op")),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"VirtualMemoryBenchmark.testPutIntLegacy"),(0,o.kt)("td",{parentName:"tr",align:null},"avgt"),(0,o.kt)("td",{parentName:"tr",align:null},"5"),(0,o.kt)("td",{parentName:"tr",align:null},"5692.148"),(0,o.kt)("td",{parentName:"tr",align:null},"ns/op")))),(0,o.kt)("h3",{id:"64-bit-read"},"64-bit Read"),(0,o.kt)("table",null,(0,o.kt)("thead",{parentName:"table"},(0,o.kt)("tr",{parentName:"thead"},(0,o.kt)("th",{parentName:"tr",align:null},"Benchmark"),(0,o.kt)("th",{parentName:"tr",align:null},"Mode"),(0,o.kt)("th",{parentName:"tr",align:null},"Cnt"),(0,o.kt)("th",{parentName:"tr",align:null},"Score"),(0,o.kt)("th",{parentName:"tr",align:null},"Units"))),(0,o.kt)("tbody",{parentName:"table"},(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"VirtualMemoryLongReadBenchmark.testLongContiguous"),(0,o.kt)("td",{parentName:"tr",align:null},"avgt"),(0,o.kt)("td",{parentName:"tr",align:null},"5"),(0,o.kt)("td",{parentName:"tr",align:null},"4088.338"),(0,o.kt)("td",{parentName:"tr",align:null},"ns/op")),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"VirtualMemoryLongReadBenchmark.testLongLegacy"),(0,o.kt)("td",{parentName:"tr",align:null},"avgt"),(0,o.kt)("td",{parentName:"tr",align:null},"5"),(0,o.kt)("td",{parentName:"tr",align:null},"5022.875"),(0,o.kt)("td",{parentName:"tr",align:null},"ns/op")))),(0,o.kt)("h3",{id:"64-bit-write"},"64-bit Write"),(0,o.kt)("table",null,(0,o.kt)("thead",{parentName:"table"},(0,o.kt)("tr",{parentName:"thead"},(0,o.kt)("th",{parentName:"tr",align:null},"Benchmark"),(0,o.kt)("th",{parentName:"tr",align:null},"Mode"),(0,o.kt)("th",{parentName:"tr",align:null},"Cnt"),(0,o.kt)("th",{parentName:"tr",align:null},"Score"),(0,o.kt)("th",{parentName:"tr",align:null},"Units"))),(0,o.kt)("tbody",{parentName:"table"},(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"VirtualMemoryLongWriteBenchmark.testPutLongContiguous"),(0,o.kt)("td",{parentName:"tr",align:null},"avgt"),(0,o.kt)("td",{parentName:"tr",align:null},"5"),(0,o.kt)("td",{parentName:"tr",align:null},"4413.181"),(0,o.kt)("td",{parentName:"tr",align:null},"ns/op")),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"VirtualMemoryLongWriteBenchmark.testPutLongLegacy"),(0,o.kt)("td",{parentName:"tr",align:null},"avgt"),(0,o.kt)("td",{parentName:"tr",align:null},"5"),(0,o.kt)("td",{parentName:"tr",align:null},"6976.593"),(0,o.kt)("td",{parentName:"tr",align:null},"ns/op")))),(0,o.kt)("p",null,"And here are the results for strings, which represent 100 reads/writes:"),(0,o.kt)("h3",{id:"string-read"},"String Read"),(0,o.kt)("table",null,(0,o.kt)("thead",{parentName:"table"},(0,o.kt)("tr",{parentName:"thead"},(0,o.kt)("th",{parentName:"tr",align:null},"Benchmark"),(0,o.kt)("th",{parentName:"tr",align:null},"Mode"),(0,o.kt)("th",{parentName:"tr",align:null},"Cnt"),(0,o.kt)("th",{parentName:"tr",align:null},"Score"),(0,o.kt)("th",{parentName:"tr",align:null},"Units"))),(0,o.kt)("tbody",{parentName:"table"},(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"VirtualMemoryStrReadBenchmark.testGetStrContiguous"),(0,o.kt)("td",{parentName:"tr",align:null},"avgt"),(0,o.kt)("td",{parentName:"tr",align:null},"5"),(0,o.kt)("td",{parentName:"tr",align:null},"300.346"),(0,o.kt)("td",{parentName:"tr",align:null},"ns/op")),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"VirtualMemoryStrReadBenchmark.testGetStrLegacy"),(0,o.kt)("td",{parentName:"tr",align:null},"avgt"),(0,o.kt)("td",{parentName:"tr",align:null},"5"),(0,o.kt)("td",{parentName:"tr",align:null},"525.775"),(0,o.kt)("td",{parentName:"tr",align:null},"ns/op")),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"VirtualMemoryStrWriteBenchmark.testPutStrContiguous"),(0,o.kt)("td",{parentName:"tr",align:null},"avgt"),(0,o.kt)("td",{parentName:"tr",align:null},"5"),(0,o.kt)("td",{parentName:"tr",align:null},"2.019"),(0,o.kt)("td",{parentName:"tr",align:null},"ns/op")),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"VirtualMemoryStrWriteBenchmark.testPutStrLegacy"),(0,o.kt)("td",{parentName:"tr",align:null},"avgt"),(0,o.kt)("td",{parentName:"tr",align:null},"5"),(0,o.kt)("td",{parentName:"tr",align:null},"3.646"),(0,o.kt)("td",{parentName:"tr",align:null},"ns/op")))),(0,o.kt)("p",null,"For those of you that are more graphicly-inclined:"),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"Benchmark showing the relative performance of primitive types",src:a(28608).Z})),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"Benchmark showing the relative performance of string types",src:a(49564).Z})),(0,o.kt)("p",null,"Again, we think these numbers speak for themselves, but we're always happy to\nhear from you, our users and community, about what you think."))}h.isMDXComponent=!0},86010:function(e,t,a){function n(e){var t,a,r="";if("string"==typeof e||"number"==typeof e)r+=e;else if("object"==typeof e)if(Array.isArray(e))for(t=0;t<e.length;t++)e[t]&&(a=n(e[t]))&&(r&&(r+=" "),r+=a);else for(t in e)e[t]&&(r&&(r+=" "),r+=t);return r}function r(){for(var e,t,a=0,r="";a<arguments.length;)(e=arguments[a++])&&(t=n(e))&&(r&&(r+=" "),r+=t);return r}a.d(t,{Z:function(){return r}})},28608:function(e,t,a){t.Z=a.p+"assets/images/primitives-20aae46c1b4abd47c5142c524ebbc624.png"},49564:function(e,t,a){t.Z=a.p+"assets/images/strings-c15a13ab0f60a61ddfcc943ad4050780.png"}}]);