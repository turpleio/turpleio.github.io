"use strict";(self.webpackChunkquestdb_io=self.webpackChunkquestdb_io||[]).push([[834],{3905:function(e,t,n){n.d(t,{Zo:function(){return p},kt:function(){return c}});var a=n(67294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function r(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var l=a.createContext({}),h=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},p=function(e){var t=h(e.components);return a.createElement(l.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},d=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,i=e.originalType,l=e.parentName,p=r(e,["components","mdxType","originalType","parentName"]),d=h(n),c=o,m=d["".concat(l,".").concat(c)]||d[c]||u[c]||i;return n?a.createElement(m,s(s({ref:t},p),{},{components:n})):a.createElement(m,s({ref:t},p))}));function c(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var i=n.length,s=new Array(i);s[0]=d;var r={};for(var l in t)hasOwnProperty.call(t,l)&&(r[l]=t[l]);r.originalType=e,r.mdxType="string"==typeof e?e:o,s[1]=r;for(var h=2;h<i;h++)s[h]=n[h];return a.createElement.apply(null,s)}return a.createElement.apply(null,n)}d.displayName="MDXCreateElement"},28728:function(e,t,n){n.r(t),n.d(t,{frontMatter:function(){return l},metadata:function(){return h},toc:function(){return p},default:function(){return d}});var a=n(83117),o=n(80102),i=(n(67294),n(3905)),s=n(72525),r=["components"],l={title:"Demo geospatial and timeseries queries on 250k unique devices",author:"Vlad Ilyushchenko",author_title:"QuestDB Team",author_url:"https://github.com/bluestreak01",author_image_url:"https://avatars.githubusercontent.com/bluestreak01",description:"We now support geospatial data in our time series database by adding geohashes to our type system along with language features to support common operations using this type.",keywords:["geospatial","timeseries","database","geodata","postgis"],image:"/img/blog/2021-10-04/banner.png",tags:["demo","release","engineering","geospatial","postgis"]},h={permalink:"/blog/2021/10/04/geospatial-timeseries-demo",source:"@site/blog/2021-10-04-geospatial-timeseries-demo.md",title:"Demo geospatial and timeseries queries on 250k unique devices",description:"We now support geospatial data in our time series database by adding geohashes to our type system along with language features to support common operations using this type.",date:"2021-10-04T00:00:00.000Z",formattedDate:"October 4, 2021",tags:[{label:"demo",permalink:"/blog/tags/demo"},{label:"release",permalink:"/blog/tags/release"},{label:"engineering",permalink:"/blog/tags/engineering"},{label:"geospatial",permalink:"/blog/tags/geospatial"},{label:"postgis",permalink:"/blog/tags/postgis"}],readingTime:10.395,truncated:!0,prevItem:{title:"Real-time stock price dashboard using QuestDB, Python and Plotly",permalink:"/blog/2021/11/01/plotly-finnhub-realtime-dashboard"},nextItem:{title:"Join Hacktoberfest 2021 and contribute to QuestDB!",permalink:"/blog/2021/10/01/hacktoberfest-questdb"}},p=[{value:"What are geohashes?",id:"what-are-geohashes",children:[{value:"Mapping geohashes",id:"mapping-geohashes",children:[]}]},{value:"QuestDB geohash syntax and storage",id:"questdb-geohash-syntax-and-storage",children:[]},{value:"Optimizing for common usage patterns",id:"optimizing-for-common-usage-patterns",children:[{value:"Functions and operators",id:"functions-and-operators",children:[]}]},{value:"What we learned",id:"what-we-learned",children:[]}],u={toc:p};function d(e){var t=e.components,n=(0,o.Z)(e,r);return(0,i.kt)("wrapper",(0,a.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("p",null,"The last significant features we shipped dealt with out-of-order data ingestion,\nand we focused our efforts on hitting the highest write-throughput that we could\nachieve for that release. Our latest feature highlight adds space as a new\ndimension that our database can manage and allows users to work with data sets\nthat have spatial and time components."),(0,i.kt)("p",null,"We shipped an initial implementation with software release version 6.0.5, and\nwe've updated ",(0,i.kt)("a",{parentName:"p",href:"https://demo.questdb.io/"},"our demo instance")," so anyone can test\nthese features out. To help with running queries on this sort of data, we've\nincluded an example data set which simulates 250,000 moving objects, and we've\nprovided examples in the SQL editor to demo common types of queries."),(0,i.kt)("p",null,"This blog post is mainly for people who work with geospatial data struggling\nwith performance, are looking for new tooling, or need to track changes in\ngeodata over time. This post should also be interesting for those who want to\nread about how we added geospatial support to our time series database from a\ntechnical perspective."),(0,i.kt)("h2",{id:"what-are-geohashes"},"What are geohashes?"),(0,i.kt)("p",null,"Geohashes work by dividing the Earth into 32 separate grids, and each grid is\nassigned an alphanumeric character. We can increase the precision by\nsub-dividing each grid into 32 again and adding a new alphanumeric character.\nThe result is a base32 alphanumeric string that we call a geohash, with greater\nprecision obtained with longer-length strings."),(0,i.kt)(s.Z,{alt:"An illustration showing two maps with different geohash precision levels applied",height:598,src:"/img/blog/2021-09-13/geohashes.png",width:650,mdxType:"Screenshot"}),(0,i.kt)("p",null,"To support geospatial data, we added a new ",(0,i.kt)("inlineCode",{parentName:"p"},"geohash")," type which would allow\nspecial handling of geohashes. We'll take a look at the syntax we introduced in\nthe ",(0,i.kt)("a",{parentName:"p",href:"#questdb-geohash-syntax-and-storage"},"language additions section below"),", but\nfirst, let's get an idea of what a geohash represents in terms of geographic\narea, we can take a few examples and compare the resulting grid size:"),(0,i.kt)("table",null,(0,i.kt)("thead",{parentName:"table"},(0,i.kt)("tr",{parentName:"thead"},(0,i.kt)("th",{parentName:"tr",align:null},"Type"),(0,i.kt)("th",{parentName:"tr",align:null},"Example"),(0,i.kt)("th",{parentName:"tr",align:null},"Area (precision)"))),(0,i.kt)("tbody",{parentName:"table"},(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"geohash(1c)")),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"u")),(0,i.kt)("td",{parentName:"tr",align:null},"5,000km \xd7 5,000km")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"geohash(3c)")),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"u33")),(0,i.kt)("td",{parentName:"tr",align:null},"156km \xd7 156km")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"geohash(6c)")),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"u33d8b")),(0,i.kt)("td",{parentName:"tr",align:null},"1.22km \xd7 0.61km")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"geohash(12c)")),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"u33d8b121234")),(0,i.kt)("td",{parentName:"tr",align:null},"37.2mm \xd7 18.6mm")))),(0,i.kt)("h3",{id:"mapping-geohashes"},"Mapping geohashes"),(0,i.kt)("p",null,"To place geohashes on a map, we need to know the bounding coordinates of the\ncorners of each grid. There's a very helpful script by Chris Veness that allows\nusers to input latitude and longitude coordinates and\n",(0,i.kt)("a",{parentName:"p",href:"https://www.movable-type.co.uk/scripts/geohash.html"},"maps the equivalent geohash"),".\nIn this case, the precision of the returned geohash is based on the decimal\nplaces of the lat/long coordinates."),(0,i.kt)("p",null,"The inverse calculation from geohash to latitude and longitude follows a similar\nlogic but instead requires creating a bounding box comprising four corners of\nthe grid. To calculate the geohash bounding box and place it on a map, we can\nuse a function similar to this example:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"# calculates the lat long bounds of a geohash\ndef bounds(geohash):\n  base32 = '0123456789bcdefghjkmnpqrstuvwxyz'\n  evenBit = True\n  latMin =  -90\n  latMax =  90\n  lonMin = -180\n  lonMax = 180\n\n  for char in geohash:\n    idx = base32.index(char)\n    for n in range(4, -1, -1):\n      bitN = idx >> n & 1\n      if evenBit:\n        # longitude\n        lonMid = (lonMin+lonMax) / 2\n        if (bitN == 1):\n          lonMin = lonMid\n        else:\n          lonMax = lonMid\n      else:\n        # latitude\n        latMid = (latMin+latMax) / 2\n        if (bitN == 1):\n          latMin = latMid\n        else:\n          latMax = latMid\n      evenBit = not evenBit\n\n  bounds = {'sw': (latMin, lonMin), 'ne': (latMax, lonMax)}\n  return bounds\n\nprint(bounds('u09tvw0r2'))\n# {'sw': (48.85744571685791, 2.3514175415039062), 'ne': (48.85748863220215, 2.3514604568481445)}\n")),(0,i.kt)("p",null,"Once we have the coordinates in latitude and longitude, we can use standard\nmapping tools to visualize geohashes by creating bounding boxes like the\nfollowing example, which uses ",(0,i.kt)("a",{parentName:"p",href:"https://plotly.com/"},"plotly")," via Python:"),(0,i.kt)(s.Z,{alt:"An example geohash plotted on a map using plotly via Python",height:598,src:"/img/blog/2021-10-04/plotly.png",width:650,mdxType:"Screenshot"}),(0,i.kt)("h2",{id:"questdb-geohash-syntax-and-storage"},"QuestDB geohash syntax and storage"),(0,i.kt)("p",null,"The syntax we chose for column definitions follows the format\n",(0,i.kt)("inlineCode",{parentName:"p"},"geohash(<precision>)")," where precision can be between one and twelve characters\nor directly binary values. Precision is specified as ",(0,i.kt)("inlineCode",{parentName:"p"},"n{units}")," where ",(0,i.kt)("inlineCode",{parentName:"p"},"units"),"\nmay be either ",(0,i.kt)("inlineCode",{parentName:"p"},"c")," for char or ",(0,i.kt)("inlineCode",{parentName:"p"},"b")," for bits (",(0,i.kt)("inlineCode",{parentName:"p"},"c")," being shorthand for 5 x ",(0,i.kt)("inlineCode",{parentName:"p"},"b"),").\nFor example, the geohash ",(0,i.kt)("inlineCode",{parentName:"p"},"u33d8b")," is represented by six characters, so we can\nstore this in a ",(0,i.kt)("inlineCode",{parentName:"p"},"geohash(6c)")," column."),(0,i.kt)("p",null,"We decided against using strings to represent geohash values as this is\ninefficient for both storage and value comparison, so we chose to add geohash\nliterals. The literal syntax that we use has the format of a single ",(0,i.kt)("inlineCode",{parentName:"p"},"#")," hash\nprefixing the geohash value for chars and two ",(0,i.kt)("inlineCode",{parentName:"p"},"##")," hashes for binary:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-questdb-sql"},"-- Create two geohash columns with different precision\nCREATE TABLE geo_data (g5c geohash(5c), g29b geohash(29b));\n-- Inserting geohash literals\nINSERT INTO geo_data VALUES(#u33d8, ##10101111100101111111101101101)\n-- Querying by geohash\nSELECT * FROM geo_data WHERE g5c = #u33d8;\n")),(0,i.kt)("p",null,"In terms of storage for geohash values internally, we use four different\ncategories based on how much storage each geohash would require. We break\ngeohashes down into the following types internally:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Up to 7-bit geohashes are stored as 1 ",(0,i.kt)("inlineCode",{parentName:"li"},"byte")),(0,i.kt)("li",{parentName:"ul"},"8-bit to 15-bit geohashes are stored in 2 ",(0,i.kt)("inlineCode",{parentName:"li"},"bytes")),(0,i.kt)("li",{parentName:"ul"},"16-bit to 31-bit geohashes are stored in 4 ",(0,i.kt)("inlineCode",{parentName:"li"},"bytes")),(0,i.kt)("li",{parentName:"ul"},"32-bit to 60-bit geohashes are stored in 8 ",(0,i.kt)("inlineCode",{parentName:"li"},"bytes"))),(0,i.kt)("p",null,"There may be cases where you need the control over storage provided by binary\nvalues but would prefer to work with character-formatted geohashes. We can do\nthis by including a suffix in the format ",(0,i.kt)("inlineCode",{parentName:"p"},"/{bits}")," where ",(0,i.kt)("inlineCode",{parentName:"p"},"bits")," is the number of\nbits from 1-60. This way, you can choose specific binary column precision for\nstorage, but the values passed around use char notation with lower precision:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-questdb-sql"},"-- insert a 5-bit geohash into a 4 bit column\nINSERT INTO my_geo_data VALUES(#a/4)\n-- insert a 20-bit geohash into an 18 bit column\nINSERT INTO my_geo_data VALUES(#u33d/18)\n")),(0,i.kt)("h2",{id:"optimizing-for-common-usage-patterns"},"Optimizing for common usage patterns"),(0,i.kt)("p",null,"Adding space as a dimension was one side of the problem, but we considered that\nmany use cases would track moving objects, and common usage patterns would\nlikely require more than optimized storage and ingestion only. Tracking moving\nobjects, for instance, is a different problem than stationary entities with a\nfixed location (like a lookup table). We wanted to enable users to have\nperformant query execution on the change of location of an entity over time.\nOptimizing these kinds of queries has two obvious solutions:"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"perform a geohash lookup first, then search these results by time, or"),(0,i.kt)("li",{parentName:"ol"},"search the data by time range, then perform a geohash search within the\nresults")),(0,i.kt)("p",null,"We benchmarked these scenarios and chose a time-based search first, followed by\ngeohash lookup for performance reasons, as we avoid scanning all non-indexed\nrows first. Because timestamp columns are already indexed, we leverage\nhigh-performance time-based search and filter the resulting (smaller) data sets.\nThe most significant performance penalty that we incur is lifting data from the\ndisk in the first place, so we try to avoid this."),(0,i.kt)("h3",{id:"functions-and-operators"},"Functions and operators"),(0,i.kt)("p",null,"We focused on internal optimizations for the ",(0,i.kt)("inlineCode",{parentName:"p"},"first()")," and ",(0,i.kt)("inlineCode",{parentName:"p"},"last()")," functions\nused in aggregate queries to make them execute faster. The optimization is\ncurrently restricted to ",(0,i.kt)("inlineCode",{parentName:"p"},"SAMPLE BY")," queries, and the functions need to be called\non symbol types with an index. The result is that there is a faster execution\ntime when you would like to retrieve the first or last-known value for a given\nobject (",(0,i.kt)("inlineCode",{parentName:"p"},"symbol"),") within an aggregate bucket."),(0,i.kt)("p",null,"To illustrate why this is useful, one example on our demo instance uses\n",(0,i.kt)("inlineCode",{parentName:"p"},"SAMPLE BY 15m")," to split the results into 15-minute aggregate buckets. When we\nuse the ",(0,i.kt)("inlineCode",{parentName:"p"},"last(lat)")," function here, we avoid lifting all data from the disk for\nthe ",(0,i.kt)("inlineCode",{parentName:"p"},"lat")," column, but instead read the row ID based on the timestamp index and\ninstead pick the last value within our aggregate bucket:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-questdb-sql"},"SELECT time, last(lat) lat, last(lon) lon, geo6 FROM pos\nWHERE id = 'YWPCEGICTJSGGBRIJCQVLJ'\nSAMPLE BY 15m;\n")),(0,i.kt)("p",null,"In order to take a snapshot of moving objects within a certain area, we\nintroduced a ",(0,i.kt)("inlineCode",{parentName:"p"},"within")," operator which evaluates if a comma-separated list of\ngeohashes is equal to or within another geohash. This operator works on\n",(0,i.kt)("inlineCode",{parentName:"p"},"LATEST BY")," queries on indexed columns, the ",(0,i.kt)("inlineCode",{parentName:"p"},"device_id")," column in this snippet,\nfor example:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-questdb-sql"},"SELECT * FROM pos LATEST BY id\nWHERE geo6 within(#ezz, #u33d8);\n")),(0,i.kt)("p",null,"The implementation of ",(0,i.kt)("inlineCode",{parentName:"p"},"within")," was designed to be used with additional\ntime-based filtering, so that we can efficiently sample data sets in terms of\ntime and space. The query performance of slicing time and space in this way\nshould be fast enough to power real-time mapping tools which make use of UI\nsliders to jog through slices of time:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-questdb-sql"},"SELECT * FROM pos LATEST BY id\nWHERE geo6 within(#wtq)\nAND time < '2021-09-19T00:00:00.000000Z';\n")),(0,i.kt)("p",null,"We wanted high-performance prefix-based searches that can execute across\nhundreds of thousands of unique values for this operator. To perform this in a\nnon-naive way, have a 'map-reduce' approach which splits keys into groups and\nperforms operations upon such groups in parallel. For ",(0,i.kt)("inlineCode",{parentName:"p"},"within"),", a task\nprocessing queue slices a range of geohashes, and our worker pool performs\nprefix matching:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-cpp",metastring:'title="Vanilla C++ implementation"',title:'"Vanilla',"C++":!0,'implementation"':!0},"template<typename T>\nvoid filter_with_prefix_generic_vanilla(\n        const T *hashes,\n        int64_t *rows,\n        int64_t rows_count,\n        const int64_t *prefixes,\n        int64_t prefixes_count,\n        int64_t *out_filtered_count\n) {\n    int64_t i = 0; // input index\n    int64_t o = 0; // output index\n    for (; i < rows_count; ++i) {\n        const T current_hash = hashes[to_local_row_id(rows[i] - 1)];\n        bool hit = false;\n        for (size_t j = 0, sz = prefixes_count/2; j < sz; ++j) {\n            const T hash = static_cast<T>(prefixes[2*j]);\n            const T mask = static_cast<T>(prefixes[2*j+1]);\n            hit |= (current_hash & mask) == hash;\n        }\n        if (hit) {\n            rows[o++] = rows[i];\n        }\n    }\n    *out_filtered_count = o;\n")),(0,i.kt)("p",null,"We use SIMD across most of our subsystems and use this method for any bulk data\nprocessing. The prefix matching illustrated above has vectorized equivalent so\nthat we can perform this search operation massively in parallel:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-cpp",metastring:'title="SIMD execution of prefix matching"',title:'"SIMD',execution:!0,of:!0,prefix:!0,'matching"':!0},"template<typename T, typename TVec, typename TVecB>\nvoid filter_with_prefix_generic(\n        const T *hashes,\n        int64_t *rows,\n        int64_t rows_count,\n        const int64_t *prefixes,\n        int64_t prefixes_count,\n        int64_t *out_filtered_count\n) {\n    int64_t i = 0; // input index\n    int64_t o = 0; // output index\n\n    constexpr int step = TVec::size();\n    const int64_t limit = rows_count - step + 1;\n\n    for (; i < limit; i += step) {\n        MM_PREFETCH_T0(rows + i + 64);\n        TVec current_hashes_vec;\n        for (int j = 0; j < TVec::size(); ++j) {\n            current_hashes_vec.insert(j, hashes[to_local_row_id(rows[i + j] - 1)]);\n        }\n\n        TVecB hit_mask(false);\n        for (size_t j = 0, size = prefixes_count / 2; j < size; ++j) {\n            const T hash = static_cast<T>(prefixes[2 * j]); // narrow cast for int/short/byte cases\n            const T mask = static_cast<T>(prefixes[2 * j + 1]);\n            TVec target_hash(hash); // broadcast hash\n            TVec target_mask(mask); // broadcast mask\n            hit_mask |= (current_hashes_vec & target_mask) == target_hash;\n        }\n\n        uint64_t bits = to_bits(hit_mask);\n        if (bits != 0) {\n            while(bits) {\n                auto idx = bit_scan_forward(bits);\n                rows[o++] = rows[i + idx];\n                bits &= ~(1ull << idx);\n            }\n        }\n    }\n    // for loop same as previous example...\n    *out_filtered_count = o;\n}\n")),(0,i.kt)("p",null,"One of the benefits of SIMD-based data processing is that we do not have to rely\non external indexes. This follows our original ethos of not introducing\nadditional data structures until absolutely necessary."),(0,i.kt)("h2",{id:"what-we-learned"},"What we learned"),(0,i.kt)("p",null,"As we began working with geospatial data sets, we found that there tends to be a\nlot of data noise in specific scenarios. Specifically, we saw noisy data when\nobjects send location updates but are not moving for a particular time. Our\ninitial implementation does not solve this completely, but we are looking at\nways to add mechanisms that discard similar entries within certain bounds to\neliminate duplication of records."),(0,i.kt)("p",null,"When adding our test data set with 250k objects, we estimated the number of\nunique symbols that QuestDB could easily handle was 100k or less before\nencountering performance issues. The example data set we are currently using\nshows that we can store and query up to 250k unique symbol values or more."),(0,i.kt)("p",null,"Adding support for geospatial data was a great challenge for us, and we think we\nfound novel approaches for the storage model and optimizations for common usage\npatterns that yielded surprisingly good performance results. We're happy to\nshare our findings, and we're eagerly awaiting feedback on these features, which\nyou can try directly on our live demo or via our latest releases."),(0,i.kt)("hr",null),(0,i.kt)("p",null,"If you have have feedback or questions about this article, feel free ask in our\n",(0,i.kt)("a",{parentName:"p",href:"https://slack.questdb.io/"},"Slack Community")," or browse the\n",(0,i.kt)("a",{parentName:"p",href:"https://github.com/questdb/questdb"},"project on GitHub")," where we welcome\ncontributions of all kinds."))}d.isMDXComponent=!0},86010:function(e,t,n){function a(e){var t,n,o="";if("string"==typeof e||"number"==typeof e)o+=e;else if("object"==typeof e)if(Array.isArray(e))for(t=0;t<e.length;t++)e[t]&&(n=a(e[t]))&&(o&&(o+=" "),o+=n);else for(t in e)e[t]&&(o&&(o+=" "),o+=t);return o}function o(){for(var e,t,n=0,o="";n<arguments.length;)(e=arguments[n++])&&(t=a(e))&&(o&&(o+=" "),o+=t);return o}n.d(t,{Z:function(){return o}})}}]);