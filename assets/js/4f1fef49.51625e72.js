"use strict";(self.webpackChunkquestdb_io=self.webpackChunkquestdb_io||[]).push([[6878],{3905:function(e,t,n){n.d(t,{Zo:function(){return c},kt:function(){return m}});var a=n(67294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,i=function(e,t){if(null==e)return{};var n,a,i={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var l=a.createContext({}),u=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},c=function(e){var t=u(e.components);return a.createElement(l.Provider,{value:t},e.children)},h={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},d=a.forwardRef((function(e,t){var n=e.components,i=e.mdxType,o=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),d=u(n),m=i,p=d["".concat(l,".").concat(m)]||d[m]||h[m]||o;return n?a.createElement(p,r(r({ref:t},c),{},{components:n})):a.createElement(p,r({ref:t},c))}));function m(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var o=n.length,r=new Array(o);r[0]=d;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:i,r[1]=s;for(var u=2;u<o;u++)r[u]=n[u];return a.createElement.apply(null,r)}return a.createElement.apply(null,n)}d.displayName="MDXCreateElement"},83941:function(e,t,n){n.r(t),n.d(t,{frontMatter:function(){return l},metadata:function(){return u},toc:function(){return c},default:function(){return d}});var a=n(83117),i=n(80102),o=(n(67294),n(3905)),r=n(72525),s=["components"],l={title:"4Bn rows/sec query benchmark: Clickhouse vs QuestDB vs Timescale",author:"Andrey Pechkurov",author_title:"QuestDB Engineering",author_url:"https://github.com/puzpuzpuz",author_image_url:"https://avatars.githubusercontent.com/puzpuzpuz",description:"QuestDB 6.3 brings parallel filter execution optimization to our SQL engine allowing us to reduce both cold and hot query execution times quite dramatically.",keywords:["sql","multi-threading","performance","timeseries","database","engineering"],image:"/img/blog/2022-05-26/banner.png",tags:["benchmark","engineering","release","story","performance"]},u={permalink:"/blog/2022/05/26/query-benchmark-questdb-versus-clickhouse-timescale",source:"@site/blog/2022-05-26-query-benchmark-questdb-versus-clickhouse-timescale.md",title:"4Bn rows/sec query benchmark: Clickhouse vs QuestDB vs Timescale",description:"QuestDB 6.3 brings parallel filter execution optimization to our SQL engine allowing us to reduce both cold and hot query execution times quite dramatically.",date:"2022-05-26T00:00:00.000Z",formattedDate:"May 26, 2022",tags:[{label:"benchmark",permalink:"/blog/tags/benchmark"},{label:"engineering",permalink:"/blog/tags/engineering"},{label:"release",permalink:"/blog/tags/release"},{label:"story",permalink:"/blog/tags/story"},{label:"performance",permalink:"/blog/tags/performance"}],readingTime:12.395,truncated:!0,prevItem:{title:"QuestDB 6.4 Release Highlights",permalink:"/blog/2022/05/31/questdb-release-6-4"},nextItem:{title:"How to build a real-time crypto tracker with Redpanda and QuestDB",permalink:"/blog/2022/05/25/how-to-build-a-real-time-crypto-tracker-with-redpanda-and-questdb"}},c=[{value:"Comparing with other databases",id:"comparing-with-other-databases",children:[]},{value:"How does it work?",id:"how-does-it-work",children:[]},{value:"Speed up measurements",id:"speed-up-measurements",children:[]},{value:"What&#39;s next?",id:"whats-next",children:[]}],h={toc:c};function d(e){var t=e.components,n=(0,i.Z)(e,s);return(0,o.kt)("wrapper",(0,a.Z)({},h,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"QuestDB 6.2, our previous minor version release,\n",(0,o.kt)("a",{parentName:"p",href:"https://questdb.io/blog/2022/01/12/jit-sql-compiler"},"introduced")," JIT\n(Just-in-Time) compiler for SQL filters. As we mentioned last time, the next\nstep would be to parallelize the query execution when suitable to improve the\nexecution time even further and that's what we're going to discuss and benchmark\ntoday. QuestDB 6.3 enables JIT compiled filters by default and, what's even more\nnoticeable, includes parallel SQL filter execution optimization allowing us to\nreduce both cold and hot query execution times quite dramatically."),(0,o.kt)("p",null,"Prior to diving into the implementation details and running some before/after\nbenchmarks for QuestDB, we'll be having a friendly competition with two popular\ntime series and analytical databases, TimescaleDB and ClickHouse. The purpose of\nthe competition is nothing more but an attempt to understand whether our\nparallel filter execution is worth the hassle or not."),(0,o.kt)("h2",{id:"comparing-with-other-databases"},"Comparing with other databases"),(0,o.kt)("p",null,"Our test box is a c5a.12xlarge AWS VM running Ubuntu Server 20.04 64-bit. In\npractice, this means 48 vCPU and 96 GB RAM. The attached storage is a 1 TB gp3\nvolume configured for 1,000 MB/s throughput and 16,000 IOPS. Apart from that,\nwe'll be using QuestDB 6.3.1 with the default settings which means both parallel\nfilter execution and JIT compilation being enabled."),(0,o.kt)("p",null,"In order to make the benchmark easily reproducible, we're going to use\n",(0,o.kt)("a",{parentName:"p",href:"https://github.com/timescale/tsbs"},"TSBS")," benchmark utilities to generate the\ndata. We'll be using so-called IoT use case:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},'./tsbs_generate_data --use-case="iot" \\\n                     --seed=123 \\\n                     --scale=5000 \\\n                     --timestamp-start="2020-01-01T00:00:00Z" \\\n                     --timestamp-end="2020-07-01T00:00:00Z" \\\n                     --log-interval="60s" \\\n                     --format="influx" > /tmp/data \\\n                     /\n')),(0,o.kt)("p",null,"The above command generates six months of per-minute measurements for 5,000\ntruck IoT devices. This yields almost 1.2 billion records stored in a table\nnamed ",(0,o.kt)("inlineCode",{parentName:"p"},"readings"),"."),(0,o.kt)("p",null,"Loading the data is as simple as:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"./tsbs_load_questdb --file /tmp/data\n")),(0,o.kt)("p",null,"Now, when we have the data in the database, we're going to execute the following\nquery on the ",(0,o.kt)("inlineCode",{parentName:"p"},"readings")," table",(0,o.kt)("a",{name:"filter-query"}),":"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-questdb-sql",metastring:'title="Query 1"',title:'"Query','1"':!0},"SELECT *\nFROM readings WHERE velocity > 90.0\n AND latitude >= 7.75 AND latitude <= 7.80\n AND longitude >= 14.90 AND longitude <= 14.95;\n")),(0,o.kt)("p",null,"This (kinda synthetic) query aims to find all measurements sent from fast-moving\ntrucks in the given location. Apart from that, it has a filter on three DOUBLE\ncolumns and doesn't include analytical clauses, like GROUP BY or SAMPLE BY,\nwhich is exactly what we need."),(0,o.kt)("p",null,"Our first competitor is TimescaleDB 2.6.0 running on top of PostgreSQL 14.2. As\nthe official installation guide suggests, we made sure to run ",(0,o.kt)("inlineCode",{parentName:"p"},"timescaledb-tune"),"\nto fine-tune TimescaleDB for better performance."),(0,o.kt)("p",null,"We generate the test data with the following command:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},'./tsbs_generate_data --use-case="iot" \\\n                     --seed=123 \\\n                     --scale=5000 \\\n                     --timestamp-start="2020-01-01T00:00:00Z" \\\n                     --timestamp-end="2020-07-01T00:00:00Z" \\\n                     --log-interval="60s" \\\n                     --format="timescaledb" > /tmp/data \\\n                     /\n')),(0,o.kt)("p",null,"That's the same command as before, but with the ",(0,o.kt)("inlineCode",{parentName:"p"},"format")," argument set to\n",(0,o.kt)("inlineCode",{parentName:"p"},"timescaledb"),". Next, we load the data:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"./tsbs_load_timescaledb --pass your_pwd --file /tmp/data\n")),(0,o.kt)("p",null,"Be prepared to wait for quite a while for the data to get in this time. We\nobserved 5-8x ingestion rate difference between QuestDB and two other databases\nin this particular environment. Yet, that's nothing more but a note for anyone\nwho wants to repeat the benchmark. If you'd like learn more on the ingestion\nperformance topic, check out this\n",(0,o.kt)("a",{parentName:"p",href:"https://questdb.io/time-series-benchmark-suite/"},"blog post"),"."),(0,o.kt)("p",null,"Finally, we're able to run the first query and measure the hot execution time.\nYet, if we do it, it would take more than 15 minutes for TimescaleDB to execute\nthis query. At this point, experienced TimescaleDB ","&"," PostgreSQL users may\nsuggest us to add an index to speed up this concrete query. So, let's do that:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-questdb-sql"},"CREATE INDEX ON readings (velocity, latitude, longitude);\n")),(0,o.kt)("p",null,"With an index in place, TimescaleDB can execute the query much much faster, in\naround 4.4 seconds. To get the full picture, let's include one more contestant."),(0,o.kt)("p",null,"The third member of our competition is ClickHouse 22.4.1.752. Just like with\nTimescaleDB, the command to generate the data stays the same with only the\n",(0,o.kt)("inlineCode",{parentName:"p"},"format")," argument being set to ",(0,o.kt)("inlineCode",{parentName:"p"},"clickhouse"),". Once the data is generated, it can\nbe loaded into the database:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"./tsbs_load_clickhouse --file /tmp/data\n")),(0,o.kt)("p",null,"We're ready to do the benchmark run."),(0,o.kt)(r.Z,{alt:"A chart comparing hot query execution times of QuestDB, ClickHouse and TimescaleDB - Query 1",title:"Hot query execution times of QuestDB, ClickHouse and TimescaleDB - Query 1",height:265,src:"/img/blog/2022-05-26/filter-benchmark.png",width:700,mdxType:"Screenshot"}),(0,o.kt)("p",null,"The above chart shows that QuestDB is an order of magnitude faster than both\nTimescaleDB and ClickHouse in this specific ",(0,o.kt)("a",{parentName:"p",href:"#filter-query"},"query"),"."),(0,o.kt)("p",null,"Interestingly, an index-based scan doesn't help TimescaleDB to win the\ncompetition. This is a nice illustration of the fact that a specialized\nparallelism-friendly storage model may save you from having to deal with indexes\nand paying the additional overhead during data ingestion."),(0,o.kt)("p",null,"As the next step, let's give another popular type of query a go. In the world of\ntime series data, it's common to query only the latest rows based on a certain\nfilter. QuestDB supports that elegantly through negative LIMIT clause values. If\nwe were to query ten latest measurements sent from fast-moving, yet\nfuel-efficient trucks it would look like the following:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",2:!0,className:"language-questdb-sql",metastring:'title="Query 2 (QuestDB)"',title:'"Query','(QuestDB)"':!0},"SELECT *\nFROM readings\nWHERE velocity > 75.0 AND fuel_consumption < 10.0\nLIMIT -10;\n")),(0,o.kt)("p",null,"Notice the LIMIT -10 clause in our query. It basically asks the database to\nreturn the last 10 rows that correspond to the filter. Thanks to the implicit\nascending order based on the\n",(0,o.kt)("a",{parentName:"p",href:"https://questdb.io/docs/concept/designated-timestamp/"},"designated timestamp"),"\ncolumn, we also didn't have to specify ORDER BY clause."),(0,o.kt)("p",null,"In TimescaleDB this query would look more verbose:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",2:!0,className:"language-questdb-sql",metastring:'title="Query 2 (ClickHouse and TimescaleDB)"',title:'"Query',"(ClickHouse":!0,and:!0,'TimescaleDB)"':!0},"SELECT *\nFROM readings\nWHERE velocity > 75.0 AND fuel_consumption < 10.0\nORDER BY time DESC\nLIMIT 10;\n")),(0,o.kt)("p",null,"Here, we had to specify descending ORDER BY and LIMIT clauses. When it comes to\nClickHouse, the query would look just like for TimescaleDB with the exception of\nanother column being used to store timestamps (",(0,o.kt)("inlineCode",{parentName:"p"},"created_at")," instead of ",(0,o.kt)("inlineCode",{parentName:"p"},"time"),")."),(0,o.kt)("p",null,"How do databases from our list deal with such query? Let's measure and find out!"),(0,o.kt)(r.Z,{alt:"A chart comparing hot LIMIT query execution times of QuestDB, ClickHouse and TimescaleDB - Query 2",title:"Hot LIMIT query execution times of QuestDB, ClickHouse and TimescaleDB - Query 2",height:283,src:"/img/blog/2022-05-26/filter-with-limit-benchmark.png",width:734,mdxType:"Screenshot"}),(0,o.kt)("p",null,"This time, surprisingly or not, TimescaleDB does a better job than ClickHouse.\nThat's because, just like QuestDB, TimescaleDB filters the data starting with\nthe latest time-based partitions and stops the filtering once enough rows are\nfound. We could also add an index on the ",(0,o.kt)("inlineCode",{parentName:"p"},"velocity")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"fuel_consumption"),"\ncolumns, but it won't change the result. That's because TimescaleDB doesn't use\nthe index and does a full scan instead for this query. Thanks to such behavior,\nboth QuestDB and TimescaleDB are significantly faster than ClickHouse in the\nexercise."),(0,o.kt)("p",null,"Needless to say, that both TimescaleDB and ClickHouse are great pieces of\nengineering. Your mileage may vary and performance of your particular\napplication depends on a large number of factors. So, as with any benchmark,\ntake our results with a grain of salt and make sure to measure things on your\nown."),(0,o.kt)("p",null,"That should be it for our comparison and now it's time to discuss the design\ndecisions behind our parallel SQL filter execution."),(0,o.kt)("h2",{id:"how-does-it-work"},"How does it work?"),(0,o.kt)("p",null,"First, let's quickly recap on QuestDB's\n",(0,o.kt)("a",{parentName:"p",href:"https://questdb.io/docs/concept/storage-model/"},"storage model")," to understand\nwhy it supports efficient multi-core execution. The database has a column-based\nappend-only storage model. Data is stored in tables, with each column stored in\nits own file or multiple files in case when the table is\n",(0,o.kt)("a",{parentName:"p",href:"https://questdb.io/docs/concept/partitions"},"partitioned")," by the designated\ntimestamp."),(0,o.kt)(r.Z,{alt:"A diagram showing column file partitioning",title:"Column file layout example",height:301,src:"/img/blog/2022-05-26/storage-format.png",width:757,mdxType:"Screenshot"}),(0,o.kt)("p",null,"When a SQL filter (think, WHERE clause) is executed, the database needs to scan\nthe files for the corresponding filtered columns. As you may have already\nguessed, when the column files are large enough, or the query touches multiple\npartitions, filtering the records on a single thread is inefficient. Instead,\nthe file(s) could be split into contiguous chunks (we call them ",'"',"page\nframes",'"',"). Then, multiple threads could execute the filter on each page\nframe utilizing both CPU and disk resources in a much more optimal way."),(0,o.kt)(r.Z,{alt:"A diagram showing how parallel page frame scanning works",title:"Parallel page frame scanning example",height:403,src:"/img/blog/2022-05-26/how-filtering-works.png",width:682,mdxType:"Screenshot"}),(0,o.kt)("p",null,"We already had this optimization in place for some of the analytical types of\nqueries, but not for full or partial table scan with a filter. So, that's\nbasically what we've added in version 6.3."),(0,o.kt)("p",null,"As usual, there are edge cases and hidden reefs, so the implementation is not as\nsimple as it may sound. Say, what if your query has a filter and a LIMIT -10\nclause, just like in our recent benchmark? Then the database should execute the\nquery in parallel, fetch the last 10 records and cancel the remaining page frame\nfiltering tasks, so that there is no useless filtering done by other worker\nthreads. A similar cancellation should take place in the face of a closed PG\nWire or HTTP connection or a query execution timeout. So, as you already saw in\nthe above comparison, we made sure to handle all of these edge cases. If you're\ninterested in the implementation details, go check this lengthy\n",(0,o.kt)("a",{parentName:"p",href:"https://github.com/questdb/questdb/pull/1732"},"pull request"),"."),(0,o.kt)("p",null,"From the end user perspective, this optimization is always enabled and applies\nto non-JIT and JIT-compiled filters. But how does it improve QuestDB's\nperformance? Let's find out!"),(0,o.kt)("h2",{id:"speed-up-measurements"},"Speed up measurements"),(0,o.kt)("p",null,"We'll be using the same benchmark environment as above while using a slightly\ndifferent query to keep things simple:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-questdb-sql",metastring:'title="Query 3"',title:'"Query','3"':!0},"SELECT count(*)\nFROM readings\nWHERE velocity > 75.0 AND fuel_consumption < 10.0;\n")),(0,o.kt)("p",null,"This query counts the total number of measurements sent from fast-moving, yet\nfuel-efficient trucks."),(0,o.kt)("p",null,"First, we focus on cold execution time, i.e. situation when the column files\ndata is not in the OS page cache. Multi-threaded runs use QuestDB 6.3.1 while\nsingle-threaded ones use 6.2.0 version of the database. That's because JIT\ncompilation is only available in when parallel filter execution is on starting\nfrom 6.3. The database configuration is kept default, except for the JIT being\ndisabled or enabled in the corresponding measurements. Also notice while this\ngiven query supports JIT compilation, there is a number of\n",(0,o.kt)("a",{parentName:"p",href:"https://questdb.io/docs/concept/jit-compiler/#known-limitations"},"limitations"),"\nfor the types of the queries supported by the JIT compiler."),(0,o.kt)("p",null,"The below chart shows the cold execution times."),(0,o.kt)(r.Z,{alt:"A chart comparing cold query execution time improvements in QuestDB 6.3 - Query 3",title:"Cold query execution time improvements in QuestDB 6.3 - Query 3",height:273,src:"/img/blog/2022-05-26/before-and-after-cold-runs.png",width:718,mdxType:"Screenshot"}),(0,o.kt)("p",null,"What's that? Parallel filter execution is only two times faster. More than that,\nenabled JIT-compiled filters have almost no effect on the end result. The thing\nis that the disk is the bottleneck here."),(0,o.kt)("p",null,"Let's try to make some sense out of these results. It takes around 30.7 seconds\nfor QuestDB 6.3 to execute the query when the data is only on disk. The query\nengine has to scan two groups of column files, 182 partitions each having two 50\nMB files. This gives us around 18.2 GB of on-disk data and around 592 MB/s disk\nread rate. That's lower than the configured maximum in our EBS volume, but we\nshould keep in mind allowed 10% fluctuations from the maximum throughput and,\nwhat's even more important,\n",(0,o.kt)("a",{parentName:"p",href:"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-optimized.html"},"individual limits"),"\nfor EBS-optimized instances. Our instance type is c5a.12xlarge and, according to\nthe AWS documentation, it's limited with 594 MB/s on 128 KiB I/O which is very\nclose to our back of the envelope calculation."),(0,o.kt)("p",null,"Long story short, we're maxing out the disk with multi-threaded query execution\nwhile single-threaded execution time in version 6.2 stays the same. With this in\nmind, further instance type and volume improvements would lead to better\nperformance."),(0,o.kt)("p",null,"Things should get even more exciting when it comes to hot execution scenario, so\nthere we go. In the next and all of the subsequent benchmark runs, we measure\nthe average hot execution time for the same query."),(0,o.kt)(r.Z,{alt:"A chart comparing hot query execution time improvements in QuestDB 6.3 - Query 3",title:"Hot query execution time improvements in QuestDB 6.3 - Query 3",height:281,src:"/img/blog/2022-05-26/before-and-after-hot-runs.png",width:768,mdxType:"Screenshot"}),(0,o.kt)("p",null,"On this particular box, default QuestDB configuration leads to 16 threads being\nused for the shared worker pool. So, both 6.3 runs execute the filter on\nmultiple threads speeding up the query when compared with the 6.2 runs. Another\nobservation is almost 1x difference between JIT-compiled and non-JIT filters on\n6.3. So, even with many cores available to parallel query execution, it's a good\nidea to keep JIT compilation enabled."),(0,o.kt)("p",null,"You might have noticed a weird proportion in the above chart. Namely, the\ndifference between the execution times when JIT compilation is disabled. QuestDB\n6.2 takes 30 seconds to finish the query with a single thread, while it takes\nonly roughly 1.3 seconds on 6.3. That's 23x improvement and it's impossible to\nexplain it only with parallel processing (remember, we run the filter on 16\nthreads). So, what may be the reason?"),(0,o.kt)("p",null,"The thing is that parallel filter execution uses the same batch-based model as\nJIT-compiled filter functions. This means that the filter is executed in a\ntight, CPU-friendly loop while the resulting identifiers for the matching rows\nare stored in an intermediate array. For instance, if we restrict parallel\nfilter engine to run on a single thread which is as simple as adding\n",(0,o.kt)("inlineCode",{parentName:"p"},"shared.worker.count=1")," database setting, the query under test would execute in\naround 13.5 seconds. Thus, in this very scenario batch-based filter processing\ndone on a single thread allows us to cut down 55% of the query execution time.\nObviously, multiple threads available to the engine let it run even faster.\nRefer to this\n",(0,o.kt)("a",{parentName:"p",href:"https://questdb.io/blog/2022/01/12/jit-sql-compiler/#jit-based-filtering"},"blog post"),"\nfor more information on how we do batch-based filter processing in our SQL JIT\ncompiler."),(0,o.kt)("p",null,"There is one more optimization opportunity around the query we used here.\nNamely, in case of queries that select only simple aggregate functions, like\n",(0,o.kt)("inlineCode",{parentName:"p"},"count(*)")," or ",(0,o.kt)("inlineCode",{parentName:"p"},"max(*)"),", and no column values we could push down the functions\ninto the filter loop. As an example, the filter loop will be incrementing the\n",(0,o.kt)("inlineCode",{parentName:"p"},"count(*)")," function's counter in-place rather than doing a more generic\naccumulation of the filtered row identifiers. You could say that such queries\nare rather niche, but they could be met in various dashboard applications. Thus,\nit's something that we definitely consider adding in future."),(0,o.kt)("h2",{id:"whats-next"},"What's next?"),(0,o.kt)("p",null,"Certainly, parallel SQL filter execution introduced in 6.3 is not the final\npoint in our quest. As we've mentioned already, we have multi-threading in place\nfor aggregate queries, like SAMPLE BY or GROUP BY, but only for certain shapes\nof them. Aggregate functions push-down is another potential optimization. So\nstay tuned for further improvements!"),(0,o.kt)("p",null,"As always, we encourage our users to try out 6.3.1 release on your QuestDB\ninstances and provide feedback in our\n",(0,o.kt)("a",{parentName:"p",href:"https://slack.questdb.io/"},"Slack Community"),". You can also play with our\n",(0,o.kt)("a",{parentName:"p",href:"https://demo.questdb.io/"},"live demo")," to see how fast it executes your queries.\nAnd, of course, open-source contributions to our\n",(0,o.kt)("a",{parentName:"p",href:"https://github.com/questdb/questdb"},"project on GitHub")," are more than welcome."))}d.isMDXComponent=!0},86010:function(e,t,n){function a(e){var t,n,i="";if("string"==typeof e||"number"==typeof e)i+=e;else if("object"==typeof e)if(Array.isArray(e))for(t=0;t<e.length;t++)e[t]&&(n=a(e[t]))&&(i&&(i+=" "),i+=n);else for(t in e)e[t]&&(i&&(i+=" "),i+=t);return i}function i(){for(var e,t,n=0,i="";n<arguments.length;)(e=arguments[n++])&&(t=a(e))&&(i&&(i+=" "),i+=t);return i}n.d(t,{Z:function(){return i}})}}]);