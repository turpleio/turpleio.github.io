"use strict";(self.webpackChunkquestdb_io=self.webpackChunkquestdb_io||[]).push([[7189],{3905:function(e,t,n){n.d(t,{Zo:function(){return c},kt:function(){return d}});var a=n(67294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var l=a.createContext({}),u=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},c=function(e){var t=u(e.components);return a.createElement(l.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},p=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,i=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),p=u(n),d=r,h=p["".concat(l,".").concat(d)]||p[d]||m[d]||i;return n?a.createElement(h,o(o({ref:t},c),{},{components:n})):a.createElement(h,o({ref:t},c))}));function d(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=n.length,o=new Array(i);o[0]=p;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:r,o[1]=s;for(var u=2;u<i;u++)o[u]=n[u];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}p.displayName="MDXCreateElement"},54789:function(e,t,n){n.r(t),n.d(t,{frontMatter:function(){return l},metadata:function(){return u},toc:function(){return c},default:function(){return p}});var a=n(83117),r=n(80102),i=(n(67294),n(3905)),o=n(46092),s=["components"],l={title:"Things we learned about sums",author:"Tancrede Collard",author_title:"QuestDB Team",author_url:"https://github.com/TheTanc",author_image_url:"https://avatars.githubusercontent.com/TheTanc",description:"What we learned implementing Kahan and Neumaier compensated sum algorithms, benchmark and comparison with Clickhouse.",keywords:["performance","benchmarking","deep-dive","kahan","neumaier","database","simd","clickhouse"],tags:["engineering","benchmark","performance"],image:"/img/blog/2020-05-12/banner.png"},u={permalink:"/blog/2020/05/12/interesting-things-we-learned-about-sums",source:"@site/blog/2020-05-12-interesting-things-we-learned-about-sums.md",title:"Things we learned about sums",description:"What we learned implementing Kahan and Neumaier compensated sum algorithms, benchmark and comparison with Clickhouse.",date:"2020-05-12T00:00:00.000Z",formattedDate:"May 12, 2020",tags:[{label:"engineering",permalink:"/blog/tags/engineering"},{label:"benchmark",permalink:"/blog/tags/benchmark"},{label:"performance",permalink:"/blog/tags/performance"}],readingTime:8.52,truncated:!0,prevItem:{title:"Sending IoT sensor data from Arduino to QuestDB",permalink:"/blog/2020/06/05/iot-on-questdb"},nextItem:{title:"Aggregating billions of rows per second with SIMD",permalink:"/blog/2020/04/02/using-simd-to-aggregate-billions-of-rows-per-second"}},c=[{value:"How did we get there?",id:"how-did-we-get-there",children:[]},{value:"Contents",id:"contents",children:[]},{value:"How inaccurate floating-point operations occur",id:"how-inaccurate-floating-point-operations-occur",children:[]},{value:"Float representation and truncation accuracy loss",id:"float-representation-and-truncation-accuracy-loss",children:[]},{value:"Kahan&#39;s algorithm for compensated summation",id:"kahans-algorithm-for-compensated-summation",children:[]},{value:"Kahan implementation with SIMD instructions",id:"kahan-implementation-with-simd-instructions",children:[]},{value:"Comparing performance versus ClickHouse",id:"comparing-performance-versus-clickhouse",children:[{value:"Hardware",id:"hardware",children:[]},{value:"Test data",id:"test-data",children:[]},{value:"Storage engine",id:"storage-engine",children:[]},{value:"Commands",id:"commands",children:[]},{value:"Results",id:"results",children:[]}]},{value:"What we learned",id:"what-we-learned",children:[]}],m={toc:c};function p(e){var t=e.components,l=(0,r.Z)(e,s);return(0,i.kt)("wrapper",(0,a.Z)({},m,l,{components:t,mdxType:"MDXLayout"}),(0,i.kt)(o.Z,{alt:"Wile E. Coyote and the Road Runner cartoon",height:257,src:"/img/blog/2020-05-12/banner.png",width:655,mdxType:"Banner"}),(0,i.kt)("p",null,"In the world of databases, benchmarking performance has always been the hottest\ntopic. Who is faster for data ingestion and queries? About a month ago we\nannounced a new release with SIMD aggregations on\n",(0,i.kt)("a",{parentName:"p",href:"https://news.ycombinator.com/item?id=22803504"},"HackerNews")," and\n",(0,i.kt)("a",{parentName:"p",href:"https://www.reddit.com/r/programming/comments/fwlk0k/questdb_using_simd_to_aggregate_billions_of/"},"Reddit"),".\nFast. But were those results numerically accurate?"),(0,i.kt)("p",null,'Speed is not everything. Some of the feedback we have received pointed us toward\nthe accuracy of our results. This is something typically overlooked in the\nspace, but our sums turned out to be "naive", with small errors for large\ncomputations. By compounding a very small error over and over through a set of\noperations, it can eventually become significant enough for people to start\nworrying about it.'),(0,i.kt)("p",null,'We then went on to include an accurate summation algorithm (such as "Kahan" and\n"Neumaier" compensated sums). Now that we\'re doing the sums accurately, we\nwanted to see how it affected performance. There is typically a trade-off\nbetween speed and accuracy. However, by extracting even more performance out of\nQuestDB (see below for how we did it), we managed to compute accurate sums as\nfast as naive ones! Since comparisons to Clickhouse have been our most frequent\nquestion, we have run the numbers and the result is:\n',(0,i.kt)("a",{parentName:"p",href:"#comparison-with-clickhouse"},"2x faster for summing 1bn doubles will nulls"),"."),(0,i.kt)("p",null,"All of this is included in our new\n",(0,i.kt)("a",{parentName:"p",href:"https:///releases/tag/4.2.1"},"release 4.2.1")),(0,i.kt)("p",null,"You can find our repository on ",(0,i.kt)("a",{parentName:"p",href:"https://"},"GitHub"),". All your\n",(0,i.kt)("a",{parentName:"p",href:"https:///issues?q=is%3Aissue+is%3Aopen+sort%3Aupdated-desc"},"issues"),",\n",(0,i.kt)("a",{parentName:"p",href:"https:///pulls?q=is%3Apr+is%3Aopen+sort%3Aupdated-desc"},"pull-requests")," and\n",(0,i.kt)("a",{parentName:"p",href:"https://"},"stars")," are welcome \ud83d\ude42."),(0,i.kt)("h2",{id:"how-did-we-get-there"},"How did we get there?"),(0,i.kt)("p",null,"We used prefetch and co-routines techniques to pull data from RAM to cache in\nparallel with other CPU instructions. Our performance was previously limited by\nmemory bandwidth - using these techniques would address this and allow us to\ncompute accurate sums as fast as naive sums."),(0,i.kt)("p",null,"With the help of prefetch we implemented the fastest and most accurate summation\nwe have ever ",(0,i.kt)("a",{parentName:"p",href:"#comparison-with-clickhouse"},"tested")," - 68ms over 1bn double values\nwith nulls (versus 139ms for Clickhouse). We believe this is a significant\nadvance in terms of performance for accurate summations, and will help\ndevelopers handling intensive computations with large datasets."),(0,i.kt)("h2",{id:"contents"},"Contents"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"An ",(0,i.kt)("a",{parentName:"li",href:"#inaccurate-summation"},"introductory example")," of the problem with summing\ndoubles."),(0,i.kt)("li",{parentName:"ul"},"A ",(0,i.kt)("a",{parentName:"li",href:"#float-representation-and-truncation-accuracy-loss"},"quick glance")," at\nfloating points inaccuracies."),(0,i.kt)("li",{parentName:"ul"},"A ",(0,i.kt)("a",{parentName:"li",href:"#kahans-algorithm-for-compensated-summation"},"presentation")," of the Kahan\nalgorithm."),(0,i.kt)("li",{parentName:"ul"},"Our ",(0,i.kt)("a",{parentName:"li",href:"#implementation-with-simd-instructions"},"compensated sum implementation"),"\nusing SIMD instructions."),(0,i.kt)("li",{parentName:"ul"},"A ",(0,i.kt)("a",{parentName:"li",href:"#comparison-with-clickhouse"},"benchmark versus Clickhouse")," for naive and\naccurate summation methods.")),(0,i.kt)("h2",{id:"how-inaccurate-floating-point-operations-occur"},"How inaccurate floating-point operations occur"),(0,i.kt)("p",null,"Before we dig in, some of you might wonder how an addition can be inaccurate as\nopposed to simply right or wrong."),(0,i.kt)("p",null,"CPUs are poor at dealing with floating-point values. Arithmetics are almost\nalways wrong, with a worst-case error proportional to the number of operations\n",(0,i.kt)("inlineCode",{parentName:"p"},"n"),". As floating-point operations are intransitive, the order in which you\nperform them also has an impact on accuracy."),(0,i.kt)("p",null,"Here is an example:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-java"},"public static void main(String[] args) {\n    System.out.println(5.1+9.2);\n}\n")),(0,i.kt)("p",null,"We ask to add ",(0,i.kt)("inlineCode",{parentName:"p"},"5.1")," to ",(0,i.kt)("inlineCode",{parentName:"p"},"9.2"),". The result should be ",(0,i.kt)("inlineCode",{parentName:"p"},"14.3"),", but we get the\nfollowing instead."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"14.299999999999999\n")),(0,i.kt)("p",null,"It is a small difference (only ",(0,i.kt)("inlineCode",{parentName:"p"},"0.000000000000001"),"), but it is still wrong. To\nmake matters worse, this error can be compounded."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-java"},'public static void main(String[] args) {\n    double a = 5.1+9.2;\n    double b = a + 3.5;\n    double c = 14.3 + 3.5;\n    System.out.println("The result is: " + b);\n    System.out.print("But we expected: " + c);\n}\n')),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"The result is: 17.799999999999997\nBut we expected: 17.8\n")),(0,i.kt)("p",null,"The error has just grown to ",(0,i.kt)("inlineCode",{parentName:"p"},"0.000000000000003")," and will keep on growing as we\nadd operations."),(0,i.kt)("h2",{id:"float-representation-and-truncation-accuracy-loss"},"Float representation and truncation accuracy loss"),(0,i.kt)("p",null,"Decimal numbers are not accurately stored. This is well documented already, for\nexample on\n",(0,i.kt)("a",{parentName:"p",href:"https://stackoverflow.com/questions/588004/is-floating-point-math-broken/588014#588014"},"StackOverlow"),"\nor ",(0,i.kt)("a",{parentName:"p",href:"https://0.30000000000000004.com"},"0.30000000000000004.com"),"."),(0,i.kt)("p",null,"Consequently, operations on floating points will return inaccurate results. This\nis not the only problem. Performing operations is also likely to introduce more\nerrors and to grow the total error over time. One such case is once the result\nof an operation has to be truncated to fit the original format. Here is a\nsimplified example of the ",(0,i.kt)("strong",{parentName:"p"},"truncation")," that happens when adding floats of\ndifferent orders of magnitude."),(0,i.kt)("blockquote",null,(0,i.kt)("p",{parentName:"blockquote"},"For the below example we will be using base 10 and expressing the exponent as\na number rather than a binary for sake of simplicity. We assume 5 significant\ndigits.")),(0,i.kt)("p",null,"We start with both our numbers expressed in scientific notation."),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Numbers expressed in scientific notation",src:n(33709).Z})),(0,i.kt)("p",null,"Let's expand into decimal notation and place them on a similar scale so all\ndigits fit."),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Numbers expressed in decimal notation",src:n(51501).Z})),(0,i.kt)("p",null,"Now, let us express this sum back as one number in scientific notation. We have\nto ",(0,i.kt)("inlineCode",{parentName:"p"},"truncate")," the result back to 5 significant digits."),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"A number expressed in 2 parts: the significant digits and the truncated part",src:n(76483).Z})),(0,i.kt)("p",null,"The result is incorrect. In fact, it is as if we did not sum anything."),(0,i.kt)("h2",{id:"kahans-algorithm-for-compensated-summation"},"Kahan's algorithm for compensated summation"),(0,i.kt)("p",null,"Compensated sum maintains a sum of accumulated errors and uses it to attempt to\ncorrect the (inaccurate) sum by the total error amount. It does so by trying to\nadjust each new number by the total accumulated error."),(0,i.kt)("p",null,"The main Compensated summation algorithm is the\n",(0,i.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Kahan_summation_algorithm"},"Kahan")," sum. It runs in\n4 steps:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Subtract the ",(0,i.kt)("inlineCode",{parentName:"li"},"running error")," from the new ",(0,i.kt)("inlineCode",{parentName:"li"},"number")," to get the\n",(0,i.kt)("inlineCode",{parentName:"li"},"adjusted number"),". If this is the first number, then the running error is 0."),(0,i.kt)("li",{parentName:"ul"},"Add the ",(0,i.kt)("inlineCode",{parentName:"li"},"adjusted number")," to the ",(0,i.kt)("inlineCode",{parentName:"li"},"running total")," and truncate to the number of\nsignificant digits. This is the ",(0,i.kt)("inlineCode",{parentName:"li"},"truncated result"),"."),(0,i.kt)("li",{parentName:"ul"},"Calculate the ",(0,i.kt)("inlineCode",{parentName:"li"},"new running error")," as\n",(0,i.kt)("inlineCode",{parentName:"li"},"(truncated result - running total) - adjusted number"),"."),(0,i.kt)("li",{parentName:"ul"},"Assign the ",(0,i.kt)("inlineCode",{parentName:"li"},"truncated result")," as the new ",(0,i.kt)("inlineCode",{parentName:"li"},"running total"),".")),(0,i.kt)("p",null,"This works because of addition transitivity rules."),(0,i.kt)("h2",{id:"kahan-implementation-with-simd-instructions"},"Kahan implementation with SIMD instructions"),(0,i.kt)("p",null,"Now, the interesting bit! QuestDB implements the same 4-step algorithm as Kahan.\nHowever, it uses vectorized instructions to make things a lot faster. The idea\ncame from Zach Bjornson who wrote about this on\n",(0,i.kt)("a",{parentName:"p",href:"https://blog.zachbjornson.com/2019/08/11/fast-float-summation.html"},"his blog"),"."),(0,i.kt)("p",null,"Here is our implementation in details:"),(0,i.kt)("p",null,"We first define our vectors:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-java"},"Vec8d inputVec;\nconst int step = 8;\nconst auto *lim = d + count;\nconst auto remainder = (int32_t) (count - (count / step) * step);\nconst auto *lim_vec = lim - remainder;\nVec8d sumVec = 0.;\nVec8d yVec;\nVec8d cVec = 0.;\nVec8db bVec;\nVec8q nancount = 0;\nVec8d tVec;\n")),(0,i.kt)("p",null,"Then we load vectors with data. What's happening below is exactly Kahan's\nalgorithm. However, instead of summing individual values, we are summing vectors\nof 8 values each."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-java"},"for (; d < lim_vec; d += step) {\n    _mm_prefetch(d + 63 * step, _MM_HINT_T1);\n    inputVec.load(d);\n    bVec = is_nan(inputVec);\n    nancount = if_add(bVec, nancount, 1);\n    yVec = select(bVec, 0, inputVec - cVec);\n    tVec = sumVec + yVec;\n    cVec = (tVec - sumVec) - yVec;\n    sumVec = tVec;\n}\n")),(0,i.kt)("p",null,"The strategically placed ",(0,i.kt)("inlineCode",{parentName:"p"},"prefetch")," relies on CPU pipelining. The goal is to\nhave the CPU fetching the next chunk of data from RAM to cache while we are\ncalculating the current vector."),(0,i.kt)("p",null,"Lastly, we use ",(0,i.kt)("inlineCode",{parentName:"p"},"horizontal_add")," to sum all values into a scalar value. Again, we\nrecognise Kahan's sum algorithm."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-java"},"double sum = horizontal_add(sumVec);\ndouble c = horizontal_add(cVec);\nint nans = horizontal_add(nancount);\nfor (; d < lim; d++) {\n      double x = *d;\n    if (x == x) {\n        auto y = x - c;\n        auto t = sum + y;\n        c = (t - sum) -y;\n        sum = t;\n    } else {\n        nans++;\n    }\n}\n")),(0,i.kt)("h2",{id:"comparing-performance-versus-clickhouse"},"Comparing performance versus ClickHouse"),(0,i.kt)("p",null,"We compared how performance behaves when switching from naive (inaccurate) sum\nto Kahan compensated sum."),(0,i.kt)("h3",{id:"hardware"},"Hardware"),(0,i.kt)("p",null,"We run all databases on an ",(0,i.kt)("inlineCode",{parentName:"p"},"c5.metal")," AWS instance, which has two Intel 8275CL\n24-core CPUs and 192GB of memory. QuestDB was running on 16 threads. As we\nshowed in a\n",(0,i.kt)("a",{parentName:"p",href:"/blog/2020/04/02/using-simd-to-aggregate-billions-of-rows-per-second"},"previous article"),",\nadding more threads does not improve performance beyond a certain point.\nClickhouse was running using all cores as per default configuration, however we\nincreased the memory limit from the default value from 10GB to 40GB\n",(0,i.kt)("inlineCode",{parentName:"p"},"<max_memory_usage>40000000000</max_memory_usage>"),"."),(0,i.kt)("h3",{id:"test-data"},"Test data"),(0,i.kt)("p",null,"We generated two test files using our\n",(0,i.kt)("a",{parentName:"p",href:"/docs/reference/function/random-value-generator"},"random generation functions"),"\nand exported the results to CSV. We then imported the CSV individually in the\ndatabases."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-questdb-sql"},"SELECT rnd_double() FROM long_sequence(1_000_000_000l); -- non null\nSELECT rnd_double(2) FROM long_sequence(1_000_000_000l); -- with nulls\n")),(0,i.kt)("h3",{id:"storage-engine"},"Storage engine"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"QuestDB"),": on disk"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Clickhouse"),": in memory (using the ",(0,i.kt)("inlineCode",{parentName:"li"},"memory()")," engine)")),(0,i.kt)("h3",{id:"commands"},"Commands"),(0,i.kt)("h4",{id:"with-null"},"With null"),(0,i.kt)("table",null,(0,i.kt)("thead",{parentName:"table"},(0,i.kt)("tr",{parentName:"thead"},(0,i.kt)("th",{parentName:"tr",align:null},"Description"),(0,i.kt)("th",{parentName:"tr",align:null},"QuestDB"),(0,i.kt)("th",{parentName:"tr",align:null},"Clickhouse"))),(0,i.kt)("tbody",{parentName:"table"},(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"DDL"),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"CREATE TABLE test_double AS(SELECT rnd_double() FROM long_sequence(1000000000L);")),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"CREATE TABLE test_double (val Nullable(Float64)) Engine=Memory;"))),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"Import"),(0,i.kt)("td",{parentName:"tr",align:null},"Not required"),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},'clickhouse-client --query="INSERT INTO test_double FORMAT CSVWithNames;" < test_double.csv'))),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"Naive sum"),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"SELECT sum(val) FROM test_double;")),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"SELECT sum(val) FROM test_double;"))),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"Kahan sum"),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"SELECT ksum(val) FROM test_double;")),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"SELECT sumKahan(val) FROM test_double;"))))),(0,i.kt)("h4",{id:"non-null"},"Non-null"),(0,i.kt)("p",null,"For non-null values, we adjusted the commands as follows:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"use ",(0,i.kt)("inlineCode",{parentName:"li"},"test_double_not_nul.csv")," instead of ",(0,i.kt)("inlineCode",{parentName:"li"},"test_double.csv"),"."),(0,i.kt)("li",{parentName:"ul"},"for Clickhouse, skip declaring val as ",(0,i.kt)("inlineCode",{parentName:"li"},"nullable"),":\n",(0,i.kt)("inlineCode",{parentName:"li"},"CREATE TABLE test_double_not_null (val Float64) Engine=Memory;"),"."),(0,i.kt)("li",{parentName:"ul"},"for QuestDB, replace ",(0,i.kt)("inlineCode",{parentName:"li"},"rnd_double()")," by ",(0,i.kt)("inlineCode",{parentName:"li"},"rnd_double(2)")," at the DDL step.")),(0,i.kt)("h3",{id:"results"},"Results"),(0,i.kt)("p",null,"We ran each query several times for both QuestDB and Clickhouse and kept the\nbest result."),(0,i.kt)("p",null,"Without null values, both databases sum naively at roughly the same speed. With\nKahan summation, QuestDB performs at the same speed while Clickhouse's\nperformance drops by ~40%."),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"QuestDB vs Clickhouse benchmark for Kahan&#39;s sums",src:n(9964).Z})),(0,i.kt)("p",null,"As we include null values, Clickhouse's performance degrades by 28% and 50% for\nnaive and Kahan summation, respectively."),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"QuestDB vs Clickhouse benchmark for Kahan&#39;s sums with nulls",src:n(94865).Z})),(0,i.kt)("h2",{id:"what-we-learned"},"What we learned"),(0,i.kt)("p",null,"It is useful to stabilize aggregation with compensated sums. We learned that\nvector-based calculation produce different arithmetic errors compared to\nnon-vector calculations. The way the aggregation is executed by multiple threads\nis not constant. This can cause results to be different from one SQL run to\nanother, if the sum is accuracy naive. Through compensated sums, the results are\nconsistent and more accurate."),(0,i.kt)("p",null,"It was also both interesting and surprising to be able to quantify the effect of\nprefetch on what is essentially sequential memory read."),(0,i.kt)("p",null,"Your support means a lot to us! If you like content like this, what we do, and\nwhere we're going, please ",(0,i.kt)("a",{parentName:"p",href:"https://"},"join our community")," and give us a\n",(0,i.kt)("a",{parentName:"p",href:"https://"},"star\ufe0f")," on GitHub."))}p.isMDXComponent=!0},86010:function(e,t,n){function a(e){var t,n,r="";if("string"==typeof e||"number"==typeof e)r+=e;else if("object"==typeof e)if(Array.isArray(e))for(t=0;t<e.length;t++)e[t]&&(n=a(e[t]))&&(r&&(r+=" "),r+=n);else for(t in e)e[t]&&(r&&(r+=" "),r+=t);return r}function r(){for(var e,t,n=0,r="";n<arguments.length;)(e=arguments[n++])&&(t=a(e))&&(r&&(r+=" "),r+=t);return r}n.d(t,{Z:function(){return r}})},51501:function(e,t,n){t.Z=n.p+"assets/images/digitsExpanded-3a266315a5bed656c8de128266d5f9ff.png"},76483:function(e,t,n){t.Z=n.p+"assets/images/digitsResult-5e5cff4654a26272384864c4ca550fc9.png"},9964:function(e,t,n){t.Z=n.p+"assets/images/kahanComparison-a120ecf15e76c693a639fc0af3908687.png"},94865:function(e,t,n){t.Z=n.p+"assets/images/kahanNullComparison-ce562d8fa2cafb5e8f02a72ca8b49f6b.png"},33709:function(e,t,n){t.Z=n.p+"assets/images/significantDigits-35f31cbf78ee69d254ac95ac9a5eb84a.png"}}]);