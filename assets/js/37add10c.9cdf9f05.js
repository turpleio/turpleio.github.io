"use strict";(self.webpackChunkquestdb_io=self.webpackChunkquestdb_io||[]).push([[840],{3905:function(e,t,n){n.d(t,{Zo:function(){return c},kt:function(){return h}});var a=n(67294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,i=function(e,t){if(null==e)return{};var n,a,i={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var l=a.createContext({}),d=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},c=function(e){var t=d(e.components);return a.createElement(l.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},u=a.forwardRef((function(e,t){var n=e.components,i=e.mdxType,r=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),u=d(n),h=i,m=u["".concat(l,".").concat(h)]||u[h]||p[h]||r;return n?a.createElement(m,o(o({ref:t},c),{},{components:n})):a.createElement(m,o({ref:t},c))}));function h(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var r=n.length,o=new Array(r);o[0]=u;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:i,o[1]=s;for(var d=2;d<r;d++)o[d]=n[d];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}u.displayName="MDXCreateElement"},51491:function(e,t,n){n.r(t),n.d(t,{frontMatter:function(){return l},metadata:function(){return d},toc:function(){return c},default:function(){return u}});var a=n(83117),i=n(80102),r=(n(67294),n(3905)),o=n(46092),s=["components"],l={title:"Time Series Forecasting with TensorFlow and QuestDB",author:"Gourav Singh Bais",author_title:"Guest post",author_url:"https://www.linkedin.com/in/gourav-singh-bais/",author_image_url:"https://assets-global.website-files.com/5fbfbba70f3f813561ef7b9f/620d4da15af10f3600a93e38_g.jpg",description:"Timeseries is a type of data used to train machine learning models. You may have numerical data for predicting housing prices or classification data for categorizing dog and cat breeds. It's also the special type of data used for training machine learning algorithms where time is the crucial component.",keywords:["python","finance","timeseries","tensorflow","machine learning"],image:"/img/blog/2022-06-20/banner.png",tags:["tutorial","python","tensorflow","machine learning","data science"]},d={permalink:"/blog/2022/06/20/forecasting-with-questdb-and-tensorflow",source:"@site/blog/2022-06-20-forecasting-with-questdb-and-tensorflow.md",title:"Time Series Forecasting with TensorFlow and QuestDB",description:"Timeseries is a type of data used to train machine learning models. You may have numerical data for predicting housing prices or classification data for categorizing dog and cat breeds. It's also the special type of data used for training machine learning algorithms where time is the crucial component.",date:"2022-06-20T00:00:00.000Z",formattedDate:"June 20, 2022",tags:[{label:"tutorial",permalink:"/blog/tags/tutorial"},{label:"python",permalink:"/blog/tags/python"},{label:"tensorflow",permalink:"/blog/tags/tensorflow"},{label:"machine learning",permalink:"/blog/tags/machine-learning"},{label:"data science",permalink:"/blog/tags/data-science"}],readingTime:14.08,truncated:!0,prevItem:{title:"Setting up Basic Authentication for QuestDB open source using Nginx",permalink:"/blog/2022/08/05/setting-basic-auth-nginx"},nextItem:{title:"Building a Data Pipeline using QuestDB and Confluent Kafka",permalink:"/blog/2022/06/07/data-pipeline-with-kafka-and-questdb"}},c=[{value:"Machine Learning for Timeseries Forecasting",id:"machine-learning-for-timeseries-forecasting",children:[]},{value:"TensorFlow and QuestDB",id:"tensorflow-and-questdb",children:[]},{value:"Implementing Predictive Data Analysis",id:"implementing-predictive-data-analysis",children:[{value:"Installing TensorFlow",id:"installing-tensorflow",children:[]},{value:"Installing QuestDB",id:"installing-questdb",children:[]},{value:"Importing Your Dependencies",id:"importing-your-dependencies",children:[]},{value:"Reading the Data Set",id:"reading-the-data-set",children:[]},{value:"Creating QuestDB Tables",id:"creating-questdb-tables",children:[]},{value:"Inserting the Data to QuestDB",id:"inserting-the-data-to-questdb",children:[]},{value:"Selecting the Data from QuestDB",id:"selecting-the-data-from-questdb",children:[]},{value:"Preprocessing the Data",id:"preprocessing-the-data",children:[]},{value:"Creating the Model",id:"creating-the-model",children:[]}]},{value:"Conclusion",id:"conclusion",children:[]}],p={toc:c};function u(e){var t=e.components,l=(0,i.Z)(e,s);return(0,r.kt)("wrapper",(0,a.Z)({},p,l,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"This post is contributed by\n",(0,r.kt)("a",{parentName:"p",href:"https://www.linkedin.com/in/gourav-singh-bais/"},"Gourav Singh Bais"),", who has\nwritten an excellent tutorial that shows how to build an application that uses\ntime series data to forecast trends and events using Tensorflow and QuestDB.\nThanks for the submission!"),(0,r.kt)(o.Z,{alt:"QuestDB log and Tensorflow logo",height:467,src:"/img/blog/2022-06-20/banner.png",width:650,mdxType:"Banner"}),(0,r.kt)("h2",{id:"machine-learning-for-timeseries-forecasting"},"Machine Learning for Timeseries Forecasting"),(0,r.kt)("p",null,"Machine learning is taking the world by storm, performing many tasks with\nhuman-like accuracy. In the medical field, there are now smart assistants that\ncan check your health over time. In finance, there are tools that can predict\nthe return on your investment with a reasonable degree of accuracy. In online\nmarketing, there are product recommenders that suggest specific products and\nbrands based on your purchase history."),(0,r.kt)("p",null,"In each of these fields, a different type of data can be used to train machine\nlearning models. Among them, ",(0,r.kt)("em",{parentName:"p"},"time series data")," is used for training machine\nlearning algorithms where time is the crucial component."),(0,r.kt)("p",null,"Time series data is complex and involves time-dependent features that go beyond\nthe scope of what traditional machine learning algorithms like Regression,\nClassification, and Clustering are useful for. Thankfully, there are machine\nlearning models we can use for ",(0,r.kt)("strong",{parentName:"p"},"time series forecasting"),". Predictions resulted\nfrom time series forecasting may not be wholly precise due to the variable\nnature of time, but they do provide reasonable approximations that are\napplicable in a variety of fields. Let\u2019s consider a few use cases:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Predictive maintenance:")," nowadays, IoT (internet of things), AI (artificial\nintelligence), and integrated systems are being embedded into electronic,\nmechanical, and other types of devices to make them smart. These IoT devices\nhave sensors to keep track of relevant values over time; and artificial\nintelligence, of which time series forecasting is a component, is used to\nanalyze this data and make predictions regarding the approximate time at which\ndevices may need maintenance.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Anomaly detection:")," the process of detecting the rare events and\nobservations in the functionality of systems. Identifying these events can be\nrather challenging, but time series forecasting helps by providing smart\nelements that can monitor things continuously. Cyber security, health\nmonitoring, and fraud detection in FinTech are a few examples of systems that\nmake use of time series analysis for anomaly detection.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"IoT data:"),"\n",(0,r.kt)("a",{parentName:"p",href:"https://oracle.com/in/internet-of-things/what-is-iot/"},"internet of things")," is\nnow becoming a concrete pillar of our economy. IoT devices have the ability to\nstore data on a timely basis and communicate it across other devices for\nanalysis and forecasting. One example of this is temperature prediction, in\nwhich different IoT devices are used to regularly store temperature data,\nwhile forecasting is then used to make weather-related predictions and\ndecisions.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Autoscaling decisions:")," With time series forecasting, businesses can better\nmonitor the demand for their products or solutions over time and anticipate\nfuture demand in time to scale their services accordingly.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Trading:")," Every day when the stock market opens and closes, entries are\nmade for fluctuations in seconds. A variety of databases and file storage\nsystems are used to store all of this information, and different time series\nforecasting algorithms can then be used to make price forecasts for the\nupcoming day, week, or even month."))),(0,r.kt)("p",null,"In this article, we will build and train a simple machine learning model that\nuses time series data to forecast trends and events using\n",(0,r.kt)("a",{parentName:"p",href:"https://www.tensorflow.org/"},"TensorFlow")," and ",(0,r.kt)("a",{parentName:"p",href:"https://questdb.io/"},"QuestDB"),"."),(0,r.kt)("h2",{id:"tensorflow-and-questdb"},"TensorFlow and QuestDB"),(0,r.kt)("p",null,"Time series forecasting can be carried out in different ways, including using\nvarious of machine learning algorithms like\n",(0,r.kt)("a",{parentName:"p",href:"https://machinelearningmastery.com/arima-for-time-series-forecasting-with-python/"},"ARIMA"),",\n",(0,r.kt)("a",{parentName:"p",href:"https://ai.plainenglish.io/time-series-decomposition-ets-model-using-python-4d2cd04bab77"},"ETS"),",\n",(0,r.kt)("a",{parentName:"p",href:"https://machinelearningmastery.com/exponential-smoothing-for-time-series-forecasting-in-python/#:~:text=Single%20Exponential%20Smoothing%2C%20SES%20for,smoothing%20factor%20or%20smoothing%20coefficient."},"Simple Exponential Smoothing"),",\nand\n",(0,r.kt)("a",{parentName:"p",href:"https://towardsdatascience.com/temporal-loops-intro-to-recurrent-neural-networks-for-time-series-forecasting-in-python-b0398963dc1f"},"Recurrent Neural Network (RNN)"),".\nThe RNN is a deep learning method with multiple variations itself such as\n",(0,r.kt)("a",{parentName:"p",href:"https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/"},"LSTM"),"\nand\n",(0,r.kt)("a",{parentName:"p",href:"https://towardsdatascience.com/predictive-analytics-time-series-forecasting-with-gru-and-bilstm-in-tensorflow-87588c852915"},"GRU"),".\nThese RNNs have feedback loops between the layers of the neural network. This\nmakes them ideal choices for timeseries forecasting as the network can\n\u2018remember\u2019 for previous data. The implementation of these deep learning\nalgorithms is made easier with the use of Google\u2019s\n",(0,r.kt)("a",{parentName:"p",href:"https://www.tensorflow.org/"},"TensorFlow")," library, which supports all kinds of\nneural networks and deep learning algorithms."),(0,r.kt)("p",null,"The heart of any algorithm is the data, and that\u2019s no different for time series\nforecasting. ",(0,r.kt)("strong",{parentName:"p"},"Time Series Databases")," (TSDBs) provide\n",(0,r.kt)("a",{parentName:"p",href:"https://questdb.io/blog/2020/11/26/why-timeseries-data/"},"a lot more features"),"\nfor storing and analyzing time series data as compared to traditional databases.\nFor this tutorial, my choice of TSDBs is ",(0,r.kt)("a",{parentName:"p",href:"https://questdb.io/"},(0,r.kt)("em",{parentName:"a"},"QuestDB")),", an\nopen source time series database with a focus on fast performance and ease of\nuse."),(0,r.kt)("h2",{id:"implementing-predictive-data-analysis"},"Implementing Predictive Data Analysis"),(0,r.kt)("p",null,"Now that you have a deeper awareness of time series data and time series\nanalysis, let\u2019s dive into a practical implementation by building an application\nto use this data for forecasting trends. This tutorial will use the historical\nexchange rate of USD to the INR data set, which you can download\n",(0,r.kt)("a",{parentName:"p",href:"https://excelrates.com/historical-exchange-rates/USD-INR"},"here")," in Excel\nformat. Make sure you select the time span between 1999-2022. This data set\ncontains three columns:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("strong",{parentName:"li"},"Date:")," time component that represents date of exchange rate."),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("strong",{parentName:"li"},"USD:")," price of USD in USD (constant 1.0)."),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("strong",{parentName:"li"},"INR:")," price of USD in INR on the specific date.")),(0,r.kt)("p",null,"As you have read, there are many different options for time series forecasting\n(e.g., ARIMA, ETS, Simple Exponential Smoothing, RNNs, LSTMs, GRUs, etc.). This\narticle will focus on the deep learning solution\u2014using neural networks to\naccomplish time series forecasting. Using RNNs for a small amount of data can\ncause an issue called\n",(0,r.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Vanishing_gradient_problem"},"vanishing gradient"),".\nBecause of this reason, LSTMs and GRUs were introduced. Due to its architectural\nsimplicity, GRU is the best option for the small amount of data you\u2019ll be using\nin this tutorial."),(0,r.kt)("p",null,"Let\u2019s get started!"),(0,r.kt)("h3",{id:"installing-tensorflow"},"Installing TensorFlow"),(0,r.kt)("p",null,"TensorFlow can be easily installed with a Python package manager (PIP). Be sure\nto use Python 3.6 for best compatibility with TensorFlow 1.15 (as well as later\nversions). If you have ",(0,r.kt)("a",{parentName:"p",href:"https://www.anaconda.com/"},"Anaconda")," installed in your\nsystem, you can use the Anaconda prompt. For normal Python installation, you can\nuse the default command prompt and write the following command to install\nTensorFlow:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"pip install tensorflow\n")),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"Note: If you are using MacOs and get a pip error, try running instead\n",(0,r.kt)("inlineCode",{parentName:"p"},"pip install tensorflow-macos"))),(0,r.kt)("p",null,"Now we need to install a few dependencies, unless you already have them locally:"),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"pip install jupyter pandas numpy scikit-learn matplotlib openpyxl")),(0,r.kt)("h3",{id:"installing-questdb"},"Installing QuestDB"),(0,r.kt)("p",null,"To install QuestDB on any OS platform, you\u2019ll need to:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("a",{parentName:"p",href:"https://docs.docker.com/engine/install/"},"Install Docker"))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Pull the QuestDB Docker image and create a Docker container. Open your\ncommand prompt and write the following command:"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"docker run -p 9000:9000 -p 8812:8812 questdb/questdb\n")))),(0,r.kt)("p",null,"Here, 9000 is the port on which QuestDB will run, and port 8812 is for the\nPostgres wire protocol."),(0,r.kt)("ol",{start:3},(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Open another terminal and run the following command to check whether QuestDB\nis running or not:"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"docker ps\n")))),(0,r.kt)("p",null,"Alternatively, you can browse ",(0,r.kt)("strong",{parentName:"p"},"localhost:9000"),", and QuestDB should be\naccessible there."),(0,r.kt)("h3",{id:"importing-your-dependencies"},"Importing Your Dependencies"),(0,r.kt)("p",null,"Now that your dependencies are installed, it\u2019s time to start implementing the\ntime series forecasting with TensorFlow and QuestDB. If you want to clone the\nproject and follow along in your own ",(0,r.kt)("a",{parentName:"p",href:"https://jupyter.org/"},"Jupyter")," notebook,\n",(0,r.kt)("a",{parentName:"p",href:"https://github.com/gouravsinghbais/Time-Series-Forecasting-with-Tensorflow-and-QuestDB"},"here is the link"),"\nto the GitHub repo."),(0,r.kt)("p",null,"We start our local jupyter environment by running:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"jupyter notebook\n")),(0,r.kt)("p",null,"First, we import the following dependencies:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"## import dependencies\nimport numpy as np\nimport pandas as pd\n\n## deep learning dependencies\n'''\nIn case you are using python version > 3.6\nyou should import model dependencies from\ntensorflow directly instead of keras\neg. from tensorflow.keras.optimizers import *\n'''\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import Sequential\nfrom keras.layers import *\nfrom keras.optimizers import *\n\n## QuestDB dependencies\nimport io\nimport requests\nimport urllib.parse as par\n\n## timestamp dependencies\nfrom datetime import datetime\n\n## visualisation dependencies\nimport matplotlib.pyplot as plt\n%matplotlib inline\n")),(0,r.kt)("h3",{id:"reading-the-data-set"},"Reading the Data Set"),(0,r.kt)("p",null,"Once you have imported all the computation, deep learning, and visualization\ndependencies, you can go ahead and read the data set we downloaded earlier:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# read dataset using pandas library\ndf = pd.read_excel('Excelrates.xlsx')\n## check first few rows of the dataset\ndf.head()\n")),(0,r.kt)("p",null,"Since the data set that you want to read is an Excel file, you will have to use\nthe ",(0,r.kt)("inlineCode",{parentName:"p"},"read_excel()")," function provided by the ",(0,r.kt)("a",{parentName:"p",href:"https://pandas.pydata.org/"},"pandas"),"\nlibrary. Once the data set is read, you can check its first few rows with the\nhelp of the ",(0,r.kt)("inlineCode",{parentName:"p"},"head()")," function. Your data set should look something like this:"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Read Dataset",src:n(64712).Z})),(0,r.kt)("h3",{id:"creating-questdb-tables"},"Creating QuestDB Tables"),(0,r.kt)("p",null,"Now you\u2019ve seen your data set, but Excel is limited in its ability to store\nlarge amounts of data. Thus, you\u2019ll use QuestDB to store the time series data\ninstead. To do so, first make sure the QuestDB Docker container is running and\naccessible:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"## create table query\nq = '''create table excel_rates (\n           Date timestamp,\n           USD int,\n           INR double)'''\n## connect to QuestDB URL and execute the query\nr = requests.get(\"http://localhost:9000/exec?query=\" + q)\n\n## print the status code once executed the table creation query\nprint(r.status_code)\n")),(0,r.kt)("p",null,"Creating a table in QuestDB involves the same process as creating the table in\nany other database like SQL, Oracle, NoSQL, etc. Simply provide the table name,\ncolumn names, and their respective data types. Then, connect to the port where\nQuestDB is running (in this case, port 9000) and execute the query using the\nrequest module of Python. If the query execution is successful, it will return\nthe status code ",(0,r.kt)("strong",{parentName:"p"},"200"),"; if not, you will receive the status code ",(0,r.kt)("strong",{parentName:"p"},"400"),"."),(0,r.kt)("h3",{id:"inserting-the-data-to-questdb"},"Inserting the Data to QuestDB"),(0,r.kt)("p",null,"Once you have created the table, you need to store your data in it. Use the\nfollowing code to do so:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"## variables for tracking successful execution of queries\nsuccess = 0\nfail = 0\n\n## iterate over each row and store it in the QuestDB table\nfor i, row in df.iterrows():\n    date = row['Date']\n    ## convert date to datetime format to store in DB\n    date = \"'\"+date.strftime('%Y-%m-%dT%H:%M:%S.%fZ')+\"'\"\n    usd = row['USD']\n    inr = row['INR']\n        query = f'insert into excel_rates values({date}, {usd}, {inr})'\n    r = requests.get(\"http://localhost:9000/exec?query=\" + query)\n    if r.status_code == 200:\n        success += 1\n    else:\n        fail += 1\n\n## check if the execution is successful or not\nif fail > 0:\n    print(\"Rows Failed: \" + str(fail))\nif success > 0:\n    print(\"Rows inserted: \" + str(success))\n")),(0,r.kt)("p",null,"To store data in QuestDB tables, you need to use the ",(0,r.kt)("strong",{parentName:"p"},"insert")," query. As shown\nabove, iterate over each row in the data frame and insert the Date, USD, and INR\ncolumns in the database. If all the rows are inserted successfully, you will\nreceive code ",(0,r.kt)("strong",{parentName:"p"},"200"),"; if any of them fails, you\u2019ll get code ",(0,r.kt)("strong",{parentName:"p"},"400"),"."),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Note:")," error code 400 may be returned due to a data type mismatch. For\nDateTime, make sure your date is enclosed in single quotes."),(0,r.kt)("h3",{id:"selecting-the-data-from-questdb"},"Selecting the Data from QuestDB"),(0,r.kt)("p",null,"One of the great things about reading data from a database, rather than directly\nfrom a file, is that we can easily run queries running filters or aggregations.\nFor the purpose of this tutorial, instead of reading the whole dataset (over\n17000 rows, we will select only three years, representing about 2200 rows. Feel\nfree to comment out the filter to compare if our model is predicting better when\nwe train with a larger dataset."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"## select data from QuestDB\nr = requests.get(\"http://localhost:9000/exp?query=select * from excel_rates where Date in ('2022') or Date in ('2021') or Date in ('2020')\")\nrawData = r.text\n\n## convert Bytes to CSV format and read using pandas library\ndf = pd.read_csv(io.StringIO(rawData), parse_dates=['Date'])\ndf.columns\n")),(0,r.kt)("p",null,"Here, in order to retrieve the data from QuestDB, you need to use the ",(0,r.kt)("inlineCode",{parentName:"p"},"select"),"\nquery. The output of the select query is a byte array that represents the data.\nOnce the data is retrieved, you can read it using the pandas ",(0,r.kt)("inlineCode",{parentName:"p"},"read_csv()"),"\nfunction."),(0,r.kt)("h3",{id:"preprocessing-the-data"},"Preprocessing the Data"),(0,r.kt)("p",null,"At this point in the tutorial, you\u2019ve created the table, inserted data into the\ntable, and read the data from the table. Now, it\u2019s time to do some time series\nforecasting preprocessing."),(0,r.kt)("p",null,"First, you can go ahead and remove the USD column, as it contains all '1'\nvalues, and as such, it will not contribute to the forecasting in any way. To do\nso, use the following code:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"## drop USD column from the dataframe\ndf = df.drop('USD', axis=1)\n## convert Date column to datetime format\ndf['Date'] = pd.to_datetime(df[\"Date\"])\n## set Date as index\nindexed_df = df.set_index([\"Date\"], drop=True)\nindexed_df.head()\n")),(0,r.kt)("p",null,"You should now see the DataFrame as follows:"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Data",src:n(63965).Z})),(0,r.kt)("p",null,"To see how the value of INR is varying according to time, you can plot a curve\nbetween time and INR using this code:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"## plot dataframe\nindexed_df.plot()\n")),(0,r.kt)("p",null,"The plot should look something like this:"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"All data set values",src:n(50041).Z})),(0,r.kt)("p",null,"Time series forecasting is a supervised approach, which means it uses input\nfeatures and labels to do forecasting. As of now, you only have Date as an index\nand a column (INR) as a feature. To create the label, you need to shift each INR\nvalue by 1 so that INR becomes the input feature, while the shifted values would\nbe the output feature/label. You\u2019ll also need to remove the NaN values from the\ncolumns to make them suitable for training. Use the following code to do all of\nthis:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"## shift INR values by 1\nshifted_df= indexed_df.shift()\n## merge INR and Shifter INR values\nconcat_df = [indexed_df, shifted_df]\ndata = pd.concat(concat_df,axis=1)\n## Replace NaNs with 0\ndata.fillna(0, inplace=True)\ndata.head()\n")),(0,r.kt)("p",null,"Once complete, your data set should look like this:"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Preprocessed data",src:n(57025).Z})),(0,r.kt)("p",null,"Next, you need to split the data into two different categories\u2014train and test:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"## convert data to numpy array\ndata = np.array(data)\n## you can take last 500 data points as test set\ntrain , test = data[0:-500], data[-500:]\n")),(0,r.kt)("p",null,"Since there is diversity in the data (values are varying at a large scale), you\nneed to apply some scaling or normalization to the data. For this purpose, you\nwill be using ",(0,r.kt)("strong",{parentName:"p"},"MinMaxScaler"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"## Scale\nscaler = MinMaxScaler()\ntrain_scaled = scaler.fit_transform(train)\ntest_scaled = scaler.transform(test)\n\n## train data\ny_train = train_scaled[:,-1]\nX_train = train_scaled[:,0:-1]\nX_train = X_train.reshape(len(X_train),1,1)\n\n## test data\ny_test = test_scaled[:,-1]\nX_test = test_scaled[:,0:-1]\n")),(0,r.kt)("h3",{id:"creating-the-model"},"Creating the Model"),(0,r.kt)("p",null,"Now, the preprocessing is complete, and it\u2019s time to train your deep learning\n(GRU) model for time series forecasting. Use this code to do so:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"## GRU Model\nmodel = Sequential()\n## GRU layer\nmodel.add(GRU(75, input_shape=(1,1)))\n## output layer\nmodel.add(Dense(1))\noptimizer = Adam(lr=1e-3)\nmodel.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['accuracy'])\nmodel.fit(X_train, y_train, epochs=100, batch_size=20, shuffle=False)\n")),(0,r.kt)("p",null,"Above, you defined your model as sequential\u2014meaning that any layer that you are\ngoing to append later will be sequentially added to the previous one. Then, a\nGRU layer was defined with seventy-five neurons, and a dense (fully connected)\nlayer was added that works as an output layer. Since you\u2019re creating a deep\nlearning model, you also added an\n",(0,r.kt)("a",{parentName:"p",href:"https://towardsdatascience.com/optimizers-for-training-neural-network-59450d71caf6"},"optimizer"),"\nand a\n",(0,r.kt)("a",{parentName:"p",href:"https://machinelearningmastery.com/loss-and-loss-functions-for-training-deep-learning-neural-networks/"},"loss function"),".\nIn this case, ",(0,r.kt)("strong",{parentName:"p"},"\u201cAdam\u201d")," works well for GRU, and since you\u2019re dealing with\nnumerical data, ",(0,r.kt)("strong",{parentName:"p"},"mean_squared_error")," will do the trick. Finally, the model was\nfitted on the input data."),(0,r.kt)("p",null,"Once you execute the above code, your model training will start. It should look\nsomething like this:"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Model training",src:n(27795).Z})),(0,r.kt)("p",null,"Once the model is ready, you\u2019ll need to test it on the test set to check its\naccuracy:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"## make predictions for test set\nX_test = X_test.reshape(500,1,1)\ny_pred = model.predict(X_test)\n\n## visualise results\nplt.plot(y_pred, label = 'predictions')\nplt.plot(y_test, label = 'actual')\nplt.legend()\n")),(0,r.kt)("p",null,"The graphs displaying actual labels and predicted labels should look like this:"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Model testing",src:n(84007).Z})),(0,r.kt)("p",null,"As you can see, the predictions are the approximation of actual values, which\nindicates that the model is performing well enough. Since the testing data has a\nlot of points, the graph appears clustered; to take a closer look at the values,\nyou can visualize just one hundred values as well:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"## visualize results\nplt.plot(y_pred[:100], label = 'predictions')\nplt.plot(y_test[:100], label = 'actual')\nplt.legend()\n")),(0,r.kt)("p",null,"The simplified plot showing only one hundred actual and predicted values would\nbe something like this:"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Model testing",src:n(35012).Z})),(0,r.kt)("p",null,"Now, your time series forecasting model is ready, and you can use it to make\npredictions for upcoming dates. The code notebook for the full project can be\nfound\n",(0,r.kt)("a",{parentName:"p",href:"https://github.com/gouravsinghbais/Time-Series-Forecasting-with-Tensorflow-and-QuestDB"},"here"),"."),(0,r.kt)("h2",{id:"conclusion"},"Conclusion"),(0,r.kt)("p",null,"In this tutorial, you learned how to do time series forecasting using deep\nlearning framework, TensorFlow, and QuestDB. As more and more electronic and\nmechanical devices are becoming smart nowadays, handling them manually is\nceasing to be an option. To efficiently automate the maintenance of these\nmachines, you need to have the right tools in place to store and process machine\ngenerated data."),(0,r.kt)("p",null,"Traditional databases are not a good option for this, as they are more focused\non processing and writing data in transactions. Time series databases, on the\nother hand, are specially designed for storing observations at different time\nintervals. They also provide features and tools to help processing time series,\nas you have seen in this tutorial."),(0,r.kt)("p",null,"If you like this content, we'd love to know your thoughts! Feel free to\n",(0,r.kt)("a",{parentName:"p",href:"https://github.com/questdb/questdb#try-questdb"},"get started on GitHub")," and come\nsay hello ",(0,r.kt)("a",{parentName:"p",href:"https://"},"in our Slack Community"),"."))}u.isMDXComponent=!0},86010:function(e,t,n){function a(e){var t,n,i="";if("string"==typeof e||"number"==typeof e)i+=e;else if("object"==typeof e)if(Array.isArray(e))for(t=0;t<e.length;t++)e[t]&&(n=a(e[t]))&&(i&&(i+=" "),i+=n);else for(t in e)e[t]&&(i&&(i+=" "),i+=t);return i}function i(){for(var e,t,n=0,i="";n<arguments.length;)(e=arguments[n++])&&(t=a(e))&&(i&&(i+=" "),i+=t);return i}n.d(t,{Z:function(){return i}})},63965:function(e,t,n){t.Z=n.p+"assets/images/data-4d6dd4957534e6dd6abdad5c80600ebb.png"},84007:function(e,t,n){t.Z=n.p+"assets/images/model-testing-1-6e0e2992aacea1b9f8ccb948a0841620.png"},35012:function(e,t,n){t.Z=n.p+"assets/images/model-testing-2-cc101302e86df256cf3648f25fa48858.png"},27795:function(e,t,n){t.Z=n.p+"assets/images/model-training-fff413d1d6cde987637a97f30774e9d7.png"},50041:function(e,t,n){t.Z=n.p+"assets/images/plot-all-values-10d74f7477658f04b57af76741ff3999.png"},57025:function(e,t,n){t.Z=n.p+"assets/images/processed-data-fcac1015e6557839d72e720f006b51db.png"},64712:function(e,t,n){t.Z=n.p+"assets/images/read-dataset-8c6e18b2d1c6ef6ce5021b65bef4e57f.png"}}]);