"use strict";(self.webpackChunkquestdb_io=self.webpackChunkquestdb_io||[]).push([[7960],{3905:function(e,t,a){a.d(t,{Zo:function(){return h},kt:function(){return m}});var n=a(67294);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function s(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,n,i=function(e,t){if(null==e)return{};var a,n,i={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||(i[a]=e[a]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var l=n.createContext({}),c=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):s(s({},t),e)),a},h=function(e){var t=c(e.components);return n.createElement(l.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},d=n.forwardRef((function(e,t){var a=e.components,i=e.mdxType,r=e.originalType,l=e.parentName,h=o(e,["components","mdxType","originalType","parentName"]),d=c(a),m=i,p=d["".concat(l,".").concat(m)]||d[m]||u[m]||r;return a?n.createElement(p,s(s({ref:t},h),{},{components:a})):n.createElement(p,s({ref:t},h))}));function m(e,t){var a=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var r=a.length,s=new Array(r);s[0]=d;var o={};for(var l in t)hasOwnProperty.call(t,l)&&(o[l]=t[l]);o.originalType=e,o.mdxType="string"==typeof e?e:i,s[1]=o;for(var c=2;c<r;c++)s[c]=a[c];return n.createElement.apply(null,s)}return n.createElement.apply(null,a)}d.displayName="MDXCreateElement"},72499:function(e,t,a){a.r(t),a.d(t,{frontMatter:function(){return l},metadata:function(){return c},toc:function(){return h},default:function(){return d}});var n=a(83117),i=a(80102),r=(a(67294),a(3905)),s=a(72525),o=["components"],l={title:"How databases handle 10 million devices in high-cardinality benchmarks",author:"Vlad Ilyushchenko",author_title:"QuestDB Team",author_url:"https://github.com/bluestreak01",author_image_url:"https://avatars.githubusercontent.com/bluestreak01",description:"Most open source time series databases struggle with high-cardinality time series data. Learn more about high-cardinality and how to benchmark database performance with this type of data.",keywords:["clickhouse","influxdb","timescaledb","tsbs","benchmark","timeseries","database"],image:"/img/blog/2021-06-16/banner.png",tags:["benchmark","clickhouse","timescaledb","influxdb","cardinality","telegraf"]},c={permalink:"/blog/2021/06/16/high-cardinality-time-series-data-performance",source:"@site/blog/2021-06-16-high-cardinality-time-series-data-performance.md",title:"How databases handle 10 million devices in high-cardinality benchmarks",description:"Most open source time series databases struggle with high-cardinality time series data. Learn more about high-cardinality and how to benchmark database performance with this type of data.",date:"2021-06-16T00:00:00.000Z",formattedDate:"June 16, 2021",tags:[{label:"benchmark",permalink:"/blog/tags/benchmark"},{label:"clickhouse",permalink:"/blog/tags/clickhouse"},{label:"timescaledb",permalink:"/blog/tags/timescaledb"},{label:"influxdb",permalink:"/blog/tags/influxdb"},{label:"cardinality",permalink:"/blog/tags/cardinality"},{label:"telegraf",permalink:"/blog/tags/telegraf"}],readingTime:9.785,truncated:!0,prevItem:{title:"Tracking multiple cryptocurrency exchanges using a time series database",permalink:"/blog/2021/06/18/tracking-multiple-cryptocurrency-exchanges"},nextItem:{title:"How we achieved write speeds of 1.4 million rows per second",permalink:"/blog/2021/05/10/questdb-release-6-0-tsbs-benchmark"}},h=[{value:"What is high-cardinality data?",id:"what-is-high-cardinality-data",children:[]},{value:"How can I measure database performance using high-cardinality data?",id:"how-can-i-measure-database-performance-using-high-cardinality-data",children:[]},{value:"Exploring high-cardinality in a time series database benchmark",id:"exploring-high-cardinality-in-a-time-series-database-benchmark",children:[]},{value:"Why QuestDB can easily ingest time series data with high-cardinality",id:"why-questdb-can-easily-ingest-time-series-data-with-high-cardinality",children:[]},{value:"Configuring parameters to optimize ingestion on high-cardinality data",id:"configuring-parameters-to-optimize-ingestion-on-high-cardinality-data",children:[]},{value:"Next up",id:"next-up",children:[]}],u={toc:h};function d(e){var t=e.components,a=(0,i.Z)(e,o);return(0,r.kt)("wrapper",(0,n.Z)({},u,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"If you're working with large amounts of data, you've likely heard about\nhigh-cardinality or ran into issues relating to it. It might sound like an\nintimidating topic if you're unfamiliar with it, but this article explains what\ncardinality is and why it crops up often with databases of all types. IoT and\nmonitoring are use cases where high-cardinality is more likely to be a concern.\nStill, a solid understanding of this concept helps when planning general-purpose\ndatabase schemas and understanding common factors that can influence database\nperformance."),(0,r.kt)("h2",{id:"what-is-high-cardinality-data"},"What is high-cardinality data?"),(0,r.kt)("p",null,"Cardinality typically refers to the number of elements in a set's size. In the\ncontext of a time series database (TSDB), rows will usually have columns that\ncategorize the data and act like tags. Assume you have 1000 IoT devices in 20\nlocations, they're running one of 5 firmware versions, and report input from 5\ntypes of sensor per device. The cardinality of this set is 500,000 (",(0,r.kt)("strong",{parentName:"p"},"1000 x 20\nx 5 x 5"),"). This can quickly get unmanageable in some cases, as even adding and\ntracking a new firmware version for the devices would increase the set to\n600,000 (",(0,r.kt)("strong",{parentName:"p"},"1000 x 20 x 6 x 5"),")."),(0,r.kt)("p",null,"In these scenarios, experience shows that we will want to eventually get\ninsights on more kinds of information about the devices, such as application\nerrors, device state, metadata, configuration and so on. With each new tag or\ncategory we add to our data set, cardinality grows exponentially. In a database,\nhigh-cardinality boils down to the following two conditions:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"a table has many indexed columns"),(0,r.kt)("li",{parentName:"ol"},"each indexed column contains many unique values")),(0,r.kt)("h2",{id:"how-can-i-measure-database-performance-using-high-cardinality-data"},"How can I measure database performance using high-cardinality data?"),(0,r.kt)("p",null,"A popular way of measuring the throughput of time series databases is to use the\nTime Series Benchmark Suite, a collection of Go programs that generate metrics\nfrom multiple simulated systems. For measuring the performance of QuestDB, we\ncreate data in InfluxDB line protocol format, which consists of ten 'tags' and\nten 'measurements' per row."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'tsbs_generate_data --scale=100 \\\n  --timestamp-start="2016-01-01T00:00:00Z" --timestamp-end="2016-01-15T00:00:00Z" \\\n  --use-case="cpu-only" --seed=123 --log-interval="10s" --format="influx"\n')),(0,r.kt)("p",null,"If we want to influence cardinality, we can use the ",(0,r.kt)("inlineCode",{parentName:"p"},"scale")," flag, which provides\na value for the number of unique devices we want the test data set to contain.\nAs the number of devices increases, so does the number of unique identifiers\nvalues per data set, and we can control cardinality directly. Here's some\nexample output from the Time Series Benchmark Suite test data with three\ndifferent devices:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-csv"},'"hostname","region","datacenter","rack","os","arch","team","service","service_version","service_environment","usage_user","usage_system","usage_idle","usage_nice","usage_iowait","usage_irq","usage_softirq","usage_steal","usage_guest","usage_guest_nice","timestamp"\n"host_0","eu-central-1","eu-central-1a","6","Ubuntu15.10","x86","SF","19","1","test",58,2,24,61,22,63,6,44,80,38,"2016-01-01T00:00:00.000000Z"\n"host_1","us-west-1","us-west-1a","41","Ubuntu15.10","x64","NYC","9","1","staging",84,11,53,87,29,20,54,77,53,74,"2016-01-01T00:00:00.000000Z"\n"host_2","sa-east-1","sa-east-1a","89","Ubuntu16.04LTS","x86","LON","13","0","staging",29,48,5,63,17,52,60,49,93,1,"2016-01-01T00:00:00.000000Z"\n')),(0,r.kt)("p",null,"The table that we create on ingestion then stores ",(0,r.kt)("strong",{parentName:"p"},"tags")," as ",(0,r.kt)("inlineCode",{parentName:"p"},"symbol")," types.\nThis ",(0,r.kt)("inlineCode",{parentName:"p"},"symbol")," type is used to efficiently store repeating string values so that\nsimilar records may be grouped together. Columns of this type are indexed so\nthat queries across tables by symbol are faster and more efficient to execute.\nThe ",(0,r.kt)("strong",{parentName:"p"},"unique")," values per ",(0,r.kt)("inlineCode",{parentName:"p"},"symbol")," column in the benchmark test data are:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"hostname = ",(0,r.kt)("inlineCode",{parentName:"li"},"scale_val")),(0,r.kt)("li",{parentName:"ul"},"region = 3"),(0,r.kt)("li",{parentName:"ul"},"datacenter = 3"),(0,r.kt)("li",{parentName:"ul"},"rack = 3"),(0,r.kt)("li",{parentName:"ul"},"os = 2"),(0,r.kt)("li",{parentName:"ul"},"arch = 2"),(0,r.kt)("li",{parentName:"ul"},"team = 3"),(0,r.kt)("li",{parentName:"ul"},"service = 3"),(0,r.kt)("li",{parentName:"ul"},"service_version = 2"),(0,r.kt)("li",{parentName:"ul"},"service_environment = 2")),(0,r.kt)("p",null,"This means we can calculate the cardinality of our test data as:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"scale_val x 3 x 3 x 3 x 2 x 2 x 3 x 3 x 2 x 2\n# or\nscale_val x 3888\n")),(0,r.kt)("h2",{id:"exploring-high-cardinality-in-a-time-series-database-benchmark"},"Exploring high-cardinality in a time series database benchmark"),(0,r.kt)("p",null,"When we released QuestDB version 6.0,\n",(0,r.kt)("a",{parentName:"p",href:"/blog/2021/05/10/questdb-release-6-0-tsbs-benchmark"},"we included benchmark results"),"\nthat tested the performance of our new ingestion subsystem, but we didn't touch\non the subject of cardinality at all. We wanted to explore this topic in more\ndetail to see how QuestDB can handle different degrees of cardinality. We also\nthought this would be interesting to share with readers as high-cardinality is a\nwell-known topic for developers and users of databases."),(0,r.kt)("p",null,"The tests we ran for our previous benchmarks all used a scale of 4000, meaning\nwe had a cardinality of 15,552,000 for all systems. For this benchmark, we\ncreated multiple data sets with the following scale and the resulting\ncardinality:"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"scale"),(0,r.kt)("th",{parentName:"tr",align:null},"cardinality"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"100")),(0,r.kt)("td",{parentName:"tr",align:null},"388,800")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"4000")),(0,r.kt)("td",{parentName:"tr",align:null},"15,552,000")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"100000")),(0,r.kt)("td",{parentName:"tr",align:null},"388,800,000")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"1000000")),(0,r.kt)("td",{parentName:"tr",align:null},"3,888,000,000")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"10000000")),(0,r.kt)("td",{parentName:"tr",align:null},"38,880,000,000")))),(0,r.kt)("p",null,"We also wanted to see what happens when we rerun the tests and provide more\nthreads (workers) to each system to observe how a database scales with\ncardinality based on how much work it can perform in parallel. For that reason,\nwe tested each database with the scale values the table above using 4, 6, and 16\nthreads on two different hosts which have the following specifications:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"AWS EC2 m5.8xlarge instance, Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz"),(0,r.kt)("li",{parentName:"ol"},"AMD Ryzen 3970X 32-Core, GIGABYTE NVME HD")),(0,r.kt)("p",null,"The following chart compares ingestion performance from lowest to highest\ncardinality running on the AWS EC2 instance with four threads:"),(0,r.kt)(s.Z,{alt:"High-cardinality time series benchmark results showing QuestDB outperforming ClickHouse, TimescaleDB and InfluxDB when using six workers",height:415,src:"/img/blog/2021-06-16/maximum-throughput-by-device-4-threads.png",title:"TSBS results using 4 threads on AWS EC2 m5.8xlarge",width:650,mdxType:"Screenshot"}),(0,r.kt)("p",null,"Using a dataset with low cardinality of 100 devices, we hit maximum ingestion\nthroughput of 904k rows/sec, with ClickHouse performing closest at 548k\nrows/sec. However, when increasing cardinality to 10 million devices, QuestDB\nsustains 640k rows/sec, and ClickHouse ingestion decreases at a similar rate\nrelative to the device count with 345k rows/sec."),(0,r.kt)("p",null,"The other systems under test struggled with higher unique device count, with\nInfluxDB ingestion dropping to 38k rows/sec and TimescaleDB at 50k rows/sec with\n10M devices. We reran the benchmark suite on the same AWS EC2 instance and\nincreased the worker count (16 threads) to the systems under test:"),(0,r.kt)(s.Z,{alt:"High-cardinality time series benchmark results showing QuestDB outperforming ClickHouse, TimescaleDB and InfluxDB when using sixteen workers",height:415,src:"/img/blog/2021-06-16/maximum-throughput-by-device-16-threads.png",title:"TSBS results using 16 threads on AWS EC2 m5.8xlarge",width:650,mdxType:"Screenshot"}),(0,r.kt)("p",null,"QuestDB showed a mostly constant ingestion rate of 815k rows/sec with all\ndegrees of cardinality. ClickHouse could ingest 900k rows/sec but requires four\ntimes as many workers as QuestDB to achieve this rate. ClickHouse ingestion\ndrops to 409k rows/sec on the largest data set. There was no significant change\nin performance between four and sixteen workers for TimescaleDB. InfluxDB\nstruggled the most, failing to finish successfully on the largest data set."),(0,r.kt)("p",null,"We ran the same benchmarks on a separate system using the AMD Ryzen 3970X, using\n4, 6, and 16 threads to see if we could observe any changes in ingestion rates:"),(0,r.kt)(s.Z,{alt:"High-cardinality time series benchmark results showing QuestDB, ClickHouse, TimescaleDB and InfluxDB when using six workers",height:415,src:"/img/blog/2021-06-16/maximum-throughput-by-device-scale-6-threads-ryzen.png",title:"TSBS results using 6 threads on AMD Ryzen 3970X",width:650,mdxType:"Screenshot"}),(0,r.kt)("p",null,"QuestDB hits maximum throughput with 1M devices during this run, with other\nsystems performing better than on the AWS instance. We can assume that\nTimescaleDB is disk-bound as results change dramatically based on the difference\nbetween the tests run on the EC2 instance. QuestDB performance peaks when using\nfour workers and slows down at 16 workers."),(0,r.kt)("p",null,"One key observation is that QuestDB handles high-cardinality better with more\nthreads. Conversely, when cardinality is low, fewer workers lead to an overall\nhigher maximum throughput and a steeper drop in ingestion rates when going from\n1M devices to 10M. The reason for lower maximum throughput when adding more\nworkers is due to increased thread contention:"),(0,r.kt)(s.Z,{alt:"High-cardinality time series benchmark results showing ingestion performance of QuestDB when using four versus 16 threads",height:415,src:"/img/blog/2021-06-16/questdb-max-throughput-by-number-threads.png",title:"TSBS results for QuestDB using 4 and 16 threads on AWS EC2 m5.8xlarge",width:650,mdxType:"Screenshot"}),(0,r.kt)("h2",{id:"why-questdb-can-easily-ingest-time-series-data-with-high-cardinality"},"Why QuestDB can easily ingest time series data with high-cardinality"),(0,r.kt)("p",null,"There are several reasons why QuestDB can quickly ingest data of this type; one\nfactor is the data model that we use to store and index data. High-cardinality\ndata has not been a pain point for our users due to our choices when designing\nthe system architecture from day one. This storage model was chosen for\narchitectural simplicity and quick read and write operations."),(0,r.kt)("p",null,"The main reason why QuestDB can handle high-cardinality data is that we\nmassively parallelize hashmap operations on indexed columns. In addition, we use\nSIMD to do a lot of heavy lifting across the entire SQL engine, which means that\nwe can execute procedures relating to indexes and hashmap lookup in parallel\nwhere possible."),(0,r.kt)("p",null,"Users who have migrated from other time-series databases told us that degraded\nperformance from high-cardinality data manifests with most systems early, but\ntheir threshold for usability is about 300K. After running the benchmark with\nhigh-cardinality, we were pleased with our system stability with up to 10\nmillion devices without a significant performance drop."),(0,r.kt)("h2",{id:"configuring-parameters-to-optimize-ingestion-on-high-cardinality-data"},"Configuring parameters to optimize ingestion on high-cardinality data"),(0,r.kt)("p",null,"The ingestion subsystem that\n",(0,r.kt)("a",{parentName:"p",href:"https://github.com/questdb/questdb/releases"},"we shipped in version 6.0"),"\nintroduces parameters that users may configure server-wide or specific to a\ntable. These parameters specify how long to keep incoming data in memory and how\noften to merge and commit incoming data to disk. The two parameters that are\nrelevant for high-cardinality data ingestion are commit lag and the maximum\nuncommitted rows."),(0,r.kt)("p",null,"Lag refers to the expected maximum lateness of incoming data relative to the\nnewest timestamp value. When records arrive at the database with timestamp\nvalues out-of-order by the value specified in the commit lag, sort and merge\ncommits are executed. Additionally, the maximum uncommitted rows can be set on a\ntable which is a threshold for the maximum number of rows to keep in memory\nbefore sorting and committing data. The benefit of these parameters is we can\nminimize the frequency of commits depending on the characteristics of the\nincoming data:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-questdb-sql"},"alter table cpu set param commitLag=50us;\nalter table cpu set param maxUncommittedRows=10000000;\n")),(0,r.kt)("p",null,"If we take a look at the type of data that we are generating in the Time Series\nBenchmark Suite, we can see that for 10M devices, the duration of the data set\nis relatively short (defined by the timestamp ",(0,r.kt)("inlineCode",{parentName:"p"},"--timestamp-start")," and\n",(0,r.kt)("inlineCode",{parentName:"p"},"--timestamp-end")," flags):"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'tsbs_generate_data --scale=10000000 \\\n  --timestamp-start="2016-01-01T00:00:00Z" --timestamp-end="2016-01-01T0:00:36Z"\n  --log-interval="10s" --format="influx" \\\n  --use-case="cpu-only" --seed=123 > /tmp/cpu-10000000\n')),(0,r.kt)("p",null,"This command generates a data set of 36M rows and spans only 36 seconds of\nsimulated activity. With throughput at this degree, the commit lag can be a much\nsmaller value, such as 50 or 100 microseconds, and the maximum uncommitted rows\ncan be around 10M. The explanation behind these values is that we expect a much\nnarrower band of the lateness of records in terms of out-of-order data, and we\nhave an upper-bounds of 10M records in memory before a commit occurs."),(0,r.kt)("p",null,"Planning the schema of a table for high-cardinality data can also have a\nsignificant performance impact. For example, when creating a table, we can\ndesignate resources for indexed columns to know how many unique values the\nsymbol column will contain, and done via capacity as follows:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-questdb-sql"},"create table cpu (\n  hostname symbol capacity 20000000,\n  region symbol,\n  ...\n) timestamp(timestamp) partition by DAY;\n")),(0,r.kt)("p",null,"In this case, we're setting a capacity of 20M for the ",(0,r.kt)("inlineCode",{parentName:"p"},"hostname")," column, which\nwe know will contain 10M values. It's generally a good idea to specify the\ncapacity of an indexed column at about twice the expected unique values if the\ndata are out-of-order. High RAM usage is associated with using a large capacity\non indexed symbols with high-cardinality data as these values sit on the memory\nheap."),(0,r.kt)("h2",{id:"next-up"},"Next up"),(0,r.kt)("p",null,"This article shows how high-cardinality can quickly emerge in time series data\nin industrial IoT, monitoring, application data and many other scenarios. If you\nhave have feedback or questions about this article, feel free ask in our\n",(0,r.kt)("a",{parentName:"p",href:"https://slack.questdb.io/"},"Slack Community")," or browse the\n",(0,r.kt)("a",{parentName:"p",href:"https://github.com/questdb/questdb"},"project on GitHub")," where we welcome\ncontributions of all kinds."))}d.isMDXComponent=!0},86010:function(e,t,a){function n(e){var t,a,i="";if("string"==typeof e||"number"==typeof e)i+=e;else if("object"==typeof e)if(Array.isArray(e))for(t=0;t<e.length;t++)e[t]&&(a=n(e[t]))&&(i&&(i+=" "),i+=a);else for(t in e)e[t]&&(i&&(i+=" "),i+=t);return i}function i(){for(var e,t,a=0,i="";a<arguments.length;)(e=arguments[a++])&&(t=n(e))&&(i&&(i+=" "),i+=t);return i}a.d(t,{Z:function(){return i}})}}]);